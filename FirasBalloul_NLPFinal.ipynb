{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1c8d8f",
   "metadata": {},
   "source": [
    "*Libraries*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 16:42:09.776407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, ISRIStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    ")\n",
    "\n",
    "# gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "# fastText LID\n",
    "import fasttext\n",
    "\n",
    "# PyTorch / Transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification,\n",
    "    pipeline, DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, Bidirectional, GRU, LSTM, Dropout, Dense\n",
    ")\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69444e",
   "metadata": {},
   "source": [
    "*Loading Data*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5e99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/home/ubuntu/NLP/altibbi_specialty_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8f1301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specialty_id</th>\n",
       "      <th>name_ar</th>\n",
       "      <th>question_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>استشاره عيون</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>السلام عليكم ممكن دكتور مفاصل واعصاب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>عمليه الحول للكبار</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>ألم بالكتف الايسر من فترة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92554</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>اريد التحدث مع طبيبب اسنان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92555</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>عندي قلق مابعد الولاده استشارات نفسيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92556</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>هل ممكن يدكتور ان تتم عمليه اعاده الكسر بسبب ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92557</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>زوجتي تعاني من ضعف النظر درجة ٤.٥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92558</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>ابي استفسر عن النظاره الطبيه للعيون</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92559 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       specialty_id                name_ar  \\\n",
       "0                23                طب عيون   \n",
       "1                14  جراحة العظام والمفاصل   \n",
       "2                14  جراحة العظام والمفاصل   \n",
       "3                23                طب عيون   \n",
       "4                14  جراحة العظام والمفاصل   \n",
       "...             ...                    ...   \n",
       "92554            18               طب اسنان   \n",
       "92555            91            الطب النفسي   \n",
       "92556            14  جراحة العظام والمفاصل   \n",
       "92557            23                طب عيون   \n",
       "92558            23                طب عيون   \n",
       "\n",
       "                                           question_body  \n",
       "0                                           استشاره عيون  \n",
       "1                   السلام عليكم ممكن دكتور مفاصل واعصاب  \n",
       "2          عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم  \n",
       "3                                     عمليه الحول للكبار  \n",
       "4                              ألم بالكتف الايسر من فترة  \n",
       "...                                                  ...  \n",
       "92554                         اريد التحدث مع طبيبب اسنان  \n",
       "92555              عندي قلق مابعد الولاده استشارات نفسيه  \n",
       "92556  هل ممكن يدكتور ان تتم عمليه اعاده الكسر بسبب ت...  \n",
       "92557                  زوجتي تعاني من ضعف النظر درجة ٤.٥  \n",
       "92558                ابي استفسر عن النظاره الطبيه للعيون  \n",
       "\n",
       "[92559 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e61d4",
   "metadata": {},
   "source": [
    "***EDA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8706f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/1938274477.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"specialty_id\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specialty_id</th>\n",
       "      <th>name_ar</th>\n",
       "      <th>question_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>الم بالجسد والدكتور منع المسكنات لانها عندها ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>عندى كسر بالعضلة اليسار الى تحت القلب ماهى الج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>انا مريض سكر من الدرجه الثانيه ومن فتره اشعر ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>التهاب قوي بلثه والحلق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>عندى حشوه تجمليه على اسناني الاماميه بس بعد مد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>انا عندي عشرون سنه وعايز اشيل درسي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>عندي صداع قوي (شقيقه) اول مااقوم من نوم واحيان...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>لو عاوزه اعمل نظاره حفظ نظر ده بيحتاج اني اروح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>حبة في جفن العين العلوي من الداحل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>انا اعاني من السمنه كتلة جسمي فوق ال30 وتعبت م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>عندي احتباس سوايل بالجسم ابغى علاج ومهما سويت ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>زيادة وزن ١٠ ك ثبات بالوزن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>الام في جميع عضلات ومفاصل الجسم ،، النوم طوال ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>سلام عليكم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>مشكلة تعلق , ومشكله بالشخصية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    specialty_id                name_ar  \\\n",
       "0             14  جراحة العظام والمفاصل   \n",
       "1             14  جراحة العظام والمفاصل   \n",
       "2             14  جراحة العظام والمفاصل   \n",
       "3             18               طب اسنان   \n",
       "4             18               طب اسنان   \n",
       "5             18               طب اسنان   \n",
       "6             23                طب عيون   \n",
       "7             23                طب عيون   \n",
       "8             23                طب عيون   \n",
       "9             25                  تغذية   \n",
       "10            25                  تغذية   \n",
       "11            25                  تغذية   \n",
       "12            91            الطب النفسي   \n",
       "13            91            الطب النفسي   \n",
       "14            91            الطب النفسي   \n",
       "\n",
       "                                        question_body  \n",
       "0   الم بالجسد والدكتور منع المسكنات لانها عندها ج...  \n",
       "1   عندى كسر بالعضلة اليسار الى تحت القلب ماهى الج...  \n",
       "2   انا مريض سكر من الدرجه الثانيه ومن فتره اشعر ب...  \n",
       "3                              التهاب قوي بلثه والحلق  \n",
       "4   عندى حشوه تجمليه على اسناني الاماميه بس بعد مد...  \n",
       "5                  انا عندي عشرون سنه وعايز اشيل درسي  \n",
       "6   عندي صداع قوي (شقيقه) اول مااقوم من نوم واحيان...  \n",
       "7   لو عاوزه اعمل نظاره حفظ نظر ده بيحتاج اني اروح...  \n",
       "8                   حبة في جفن العين العلوي من الداحل  \n",
       "9   انا اعاني من السمنه كتلة جسمي فوق ال30 وتعبت م...  \n",
       "10  عندي احتباس سوايل بالجسم ابغى علاج ومهما سويت ...  \n",
       "11                         زيادة وزن ١٠ ك ثبات بالوزن  \n",
       "12  الام في جميع عضلات ومفاصل الجسم ،، النوم طوال ...  \n",
       "13                                         سلام عليكم  \n",
       "14                       مشكلة تعلق , ومشكله بالشخصية  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"specialty_id\").apply(\n",
    "    lambda x: x[['specialty_id', 'name_ar', 'question_body']].sample(3, random_state=42)\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b44785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Empty question_body entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for empty strings in the question_body\n",
    "empty_questions = df[df[\"question_body\"].str.strip() == \"\"]\n",
    "print(f\"\\nEmpty question_body entries: {len(empty_questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900c4712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "specialty_id     0\n",
       "name_ar          0\n",
       "question_body    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47914ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebb9b4",
   "metadata": {},
   "source": [
    "*Checking for URLS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "076fc826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specialty_id</th>\n",
       "      <th>name_ar</th>\n",
       "      <th>question_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9028</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/2ztbh8oj1y73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/r/am3jz3k5g5c080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/917i35ix94owkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17794</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>https://altib.bi/oehT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17838</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altib.bi/K3j2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29569</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>ألم مستمر أسفل الظهر، منذ سنة تقريبا مرفقا صور...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29683</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>اصابه في الركبه https://argon.truecloudjo.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32092</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>https://altibbi.com/r/1b4xr6jyzzr444k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34624</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/r/b3jkjbum5pni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39675</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altib.bi/iuic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43745</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>تورم في جهة واحدة للوجه الموضوع الو اكم سنة اش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44941</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altib.bi/bPYR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45347</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altib.bi/ESFj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45608</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>استفسار عند صحة الدواء المذكور دناه ومدى فعالي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57791</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>https://altib.bi/dNnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61068</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>https://altib.bi/LSNi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62383</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/r/8dtq32tj098oc0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64432</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>http://uaesos.com/Eyereport.pdf قمت بضغط الفحو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66203</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>https://www.altibbi.com/consultation/ask-question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67512</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/2lq1i27fvm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68451</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altib.bi/jkeb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69766</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/ae6oye1jak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70652</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>https://altibbi.com/r/b5b75fzrcx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77898</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/t2x7zngk0is0wc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82535</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/%D8%A7%D8%B3%D8% بسم الله ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83379</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>https://altib.bi/y78H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86279</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altib.bi/mCNY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87656</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/r/okgik1zmic0c0w طبيب نفسى</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90556</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>https://altibbi.com/r/xlfepp8j240s8g طبيب عظام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91506</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>https://altibbi.com/r/1ukvna3zhhw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       specialty_id                name_ar  \\\n",
       "9028             14  جراحة العظام والمفاصل   \n",
       "10249            91            الطب النفسي   \n",
       "13738            14  جراحة العظام والمفاصل   \n",
       "17794            25                  تغذية   \n",
       "17838            91            الطب النفسي   \n",
       "29569            14  جراحة العظام والمفاصل   \n",
       "29683            14  جراحة العظام والمفاصل   \n",
       "32092            23                طب عيون   \n",
       "34624            91            الطب النفسي   \n",
       "39675            91            الطب النفسي   \n",
       "43745            18               طب اسنان   \n",
       "44941            91            الطب النفسي   \n",
       "45347            14  جراحة العظام والمفاصل   \n",
       "45608            23                طب عيون   \n",
       "57791            25                  تغذية   \n",
       "61068            18               طب اسنان   \n",
       "62383            91            الطب النفسي   \n",
       "64432            23                طب عيون   \n",
       "66203            18               طب اسنان   \n",
       "67512            14  جراحة العظام والمفاصل   \n",
       "68451            91            الطب النفسي   \n",
       "69766            14  جراحة العظام والمفاصل   \n",
       "70652            23                طب عيون   \n",
       "77898            14  جراحة العظام والمفاصل   \n",
       "82535            91            الطب النفسي   \n",
       "83379            23                طب عيون   \n",
       "86279            91            الطب النفسي   \n",
       "87656            91            الطب النفسي   \n",
       "90556            14  جراحة العظام والمفاصل   \n",
       "91506            91            الطب النفسي   \n",
       "\n",
       "                                           question_body  \n",
       "9028                  https://altibbi.com/r/2ztbh8oj1y73  \n",
       "10249               https://altibbi.com/r/am3jz3k5g5c080  \n",
       "13738               https://altibbi.com/r/917i35ix94owkw  \n",
       "17794                              https://altib.bi/oehT  \n",
       "17838                              https://altib.bi/K3j2  \n",
       "29569  ألم مستمر أسفل الظهر، منذ سنة تقريبا مرفقا صور...  \n",
       "29683  اصابه في الركبه https://argon.truecloudjo.com/...  \n",
       "32092              https://altibbi.com/r/1b4xr6jyzzr444k  \n",
       "34624                 https://altibbi.com/r/b3jkjbum5pni  \n",
       "39675                              https://altib.bi/iuic  \n",
       "43745  تورم في جهة واحدة للوجه الموضوع الو اكم سنة اش...  \n",
       "44941                              https://altib.bi/bPYR  \n",
       "45347                              https://altib.bi/ESFj  \n",
       "45608  استفسار عند صحة الدواء المذكور دناه ومدى فعالي...  \n",
       "57791                              https://altib.bi/dNnt  \n",
       "61068                              https://altib.bi/LSNi  \n",
       "62383               https://altibbi.com/r/8dtq32tj098oc0  \n",
       "64432  http://uaesos.com/Eyereport.pdf قمت بضغط الفحو...  \n",
       "66203  https://www.altibbi.com/consultation/ask-question  \n",
       "67512                   https://altibbi.com/r/2lq1i27fvm  \n",
       "68451                              https://altib.bi/jkeb  \n",
       "69766                   https://altibbi.com/r/ae6oye1jak  \n",
       "70652                   https://altibbi.com/r/b5b75fzrcx  \n",
       "77898               https://altibbi.com/r/t2x7zngk0is0wc  \n",
       "82535  https://altibbi.com/%D8%A7%D8%B3%D8% بسم الله ...  \n",
       "83379                              https://altib.bi/y78H  \n",
       "86279                              https://altib.bi/mCNY  \n",
       "87656     https://altibbi.com/r/okgik1zmic0c0w طبيب نفسى  \n",
       "90556     https://altibbi.com/r/xlfepp8j240s8g طبيب عظام  \n",
       "91506                  https://altibbi.com/r/1ukvna3zhhw  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex pattern to detect URLs\n",
    "url_pattern = r'http\\S+|www\\S+|https\\S+'\n",
    "\n",
    "# Filter rows that contain URLs\n",
    "rows_with_urls = df[df['question_body'].str.contains(url_pattern, na=False)]\n",
    "\n",
    "rows_with_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cae39c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   question_body\n",
      "0                                   استشاره عيون\n",
      "1           السلام عليكم ممكن دكتور مفاصل واعصاب\n",
      "2  عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم\n",
      "3                             عمليه الحول للكبار\n",
      "4                      ألم بالكتف الايسر من فترة\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/3827396248.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['question_body'] = df['question_body'].apply(remove_urls)\n"
     ]
    }
   ],
   "source": [
    "#Funstion for removing URLs from the text\n",
    "def remove_urls(text):\n",
    "    url_pattern = r'http\\S+|www\\S+|https\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "# Apply the function to the 'question_body' column and save the result\n",
    "df['question_body'] = df['question_body'].apply(remove_urls)\n",
    "\n",
    "#check some cleaned results\n",
    "print(df[['question_body']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89504713",
   "metadata": {},
   "source": [
    "*Checking for any english words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0caeaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3267\n",
      "                                         question_body\n",
      "40   Tawuniya السلام عليكم اشعر باالالم وبروده في ا...\n",
      "49   Tawuniya حاجة الى المناقشة مع دكتور عام بسبب و...\n",
      "51   عندي الم بالضرس قوي ذهبت لدكتور الاسنان فيه خر...\n",
      "76      Tawuniya لدى ابنتي انتفاخ في الجفن مثل الكورة.\n",
      "92   لسلام عليكم انا بنت عندي ٢١ سنه سناني فيها spa...\n",
      "117  وجود خراج أسفل ال crown وأدى الى تورم المنطقة ...\n",
      "145  Tawuniya اريد طبيب اطفال لإبني عساف يكشف عليه ...\n",
      "197  السلام عليكم احتاج استشاري طب وجراحه عيون . عن...\n",
      "275  انا برضع ممكن اخد برشام او دواء شرب اسمو Nurax...\n",
      "286  شخصني طبيب الجلديه قبل سنتين ب complex apthosi...\n",
      "346  Tawuniya ابنتي الصغيره دخلت اصبعها في عيني واص...\n",
      "360                                     Tawuniya اسنان\n",
      "428      Tawuniya عندي الم بالضرس وشاكه بالحمل ايش اخذ\n",
      "448  يوجد لدي اخوة لم يكملو تعليمهم بسبب ارسالهم ال...\n",
      "472  تكلمت مع دكتوره قبل يومين في الاستشارة المجاني...\n",
      "535  Tawuniya اريد استشارة دكتور عظام بخصوص عملية ك...\n",
      "605         Tawuniya احمرار وحكه بالعين من ثلاث ايام..\n",
      "607  Tawuniya اريد استشارتكم بموضوع انا لدي الم فيه...\n",
      "626  مريض لثه، تم عمل جراحة منذ ٧ سنوات Deep scalin...\n",
      "646          Tawuniya احمرار في العين وخروج افراز منها\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/1780386837.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_english'] = df['question_body'].apply(contains_english_word)\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a question contains any English words\n",
    "def contains_english_word(text):\n",
    "    # Look for sequences of English letters (a word)\n",
    "    pattern = r'\\b[A-Za-z]+\\b'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "df['has_english'] = df['question_body'].apply(contains_english_word)\n",
    "\n",
    "# See how many questions contain English words\n",
    "print(df['has_english'].sum())\n",
    "\n",
    "# See some examples\n",
    "print(df[df['has_english']][['question_body']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f00c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          question_body  \\\n",
      "40    Tawuniya السلام عليكم اشعر باالالم وبروده في ا...   \n",
      "49    Tawuniya حاجة الى المناقشة مع دكتور عام بسبب و...   \n",
      "51    عندي الم بالضرس قوي ذهبت لدكتور الاسنان فيه خر...   \n",
      "76       Tawuniya لدى ابنتي انتفاخ في الجفن مثل الكورة.   \n",
      "92    لسلام عليكم انا بنت عندي ٢١ سنه سناني فيها spa...   \n",
      "117   وجود خراج أسفل ال crown وأدى الى تورم المنطقة ...   \n",
      "145   Tawuniya اريد طبيب اطفال لإبني عساف يكشف عليه ...   \n",
      "197   السلام عليكم احتاج استشاري طب وجراحه عيون . عن...   \n",
      "275   انا برضع ممكن اخد برشام او دواء شرب اسمو Nurax...   \n",
      "286   شخصني طبيب الجلديه قبل سنتين ب complex apthosi...   \n",
      "346   Tawuniya ابنتي الصغيره دخلت اصبعها في عيني واص...   \n",
      "360                                      Tawuniya اسنان   \n",
      "428       Tawuniya عندي الم بالضرس وشاكه بالحمل ايش اخذ   \n",
      "448   يوجد لدي اخوة لم يكملو تعليمهم بسبب ارسالهم ال...   \n",
      "472   تكلمت مع دكتوره قبل يومين في الاستشارة المجاني...   \n",
      "535   Tawuniya اريد استشارة دكتور عظام بخصوص عملية ك...   \n",
      "605          Tawuniya احمرار وحكه بالعين من ثلاث ايام..   \n",
      "607   Tawuniya اريد استشارتكم بموضوع انا لدي الم فيه...   \n",
      "626   مريض لثه، تم عمل جراحة منذ ٧ سنوات Deep scalin...   \n",
      "646           Tawuniya احمرار في العين وخروج افراز منها   \n",
      "655       Tawuniya تورم بالركبة وبحاجة الى استشارة طبية   \n",
      "676   Tawuniya الطفل عمره سنه وشهرين. لاحظت ميول في ...   \n",
      "697   دكتور أنا عندي مقاومة أنسولين من فترة طويله و ...   \n",
      "701   Tawuniya اعاني من ألم حاد بالاسنان جراء التهاب...   \n",
      "728                                 Tawuniya سلام عليكم   \n",
      "734   استخدمت قطره Dewax للعين بالخطا حيث سببت حررري...   \n",
      "787   اعانى من الام بالكتف الايسر منذ شهر استعملت Di...   \n",
      "828   ارغب الاستفسار عن هذا الدواء antabuse وهل يساع...   \n",
      "860         Tawuniya خروج افرازات خضراء وبيضاء من العين   \n",
      "875                               Tawuniya تكسر الاسنان   \n",
      "918   اعاني من Ulnar nerve sublaxatio عندي عصب ال ul...   \n",
      "972                                Tawuniya دكتور اسنان   \n",
      "1005  I’m 15 yrs old I was diagnose with t1diabetes ...   \n",
      "1039  والدتي سنها ٦٥ تعاني من خشونه ركبه و انها تاخذ...   \n",
      "1086  عندي ثنائي القطب و schizoaffective واول ما صحي...   \n",
      "1088  اعاني من فقدان شديد للوزن ومو قابله انصح وماعن...   \n",
      "1188                                      Tawuniya عيون   \n",
      "1242  اعاني من تهتك نخاع شوكي ولدي الم وتشنج في القد...   \n",
      "1277                           استشارة بخصوص علاج ridon   \n",
      "1316  Tawuniya اعاني من تورم في عظلة مابين الرقبه وا...   \n",
      "1350  Tawuniya تم رفض طلب جلسات علاج طبيعي لفقرات ال...   \n",
      "1358  حصل موقف عائلي اليوم وانفعلت وعصبت من بعدها جا...   \n",
      "1390                   Tawuniya الرقبه مقدر احركها يسار   \n",
      "1399    هل يمكن اخذ مسكن dexamethasone مع دواء cymbalta   \n",
      "1436               Tawuniya ارتخاء في عظله العين والجفن   \n",
      "1443                           Tawuniya جفاف حاد بالعين   \n",
      "1465                                Tawuniya دكتور عظام   \n",
      "1473   حرقة في العين بعد اخذ ابرة حساسية ودواء primalan   \n",
      "1483  Tawuniya السلام عليكم لدي كسر سابق بأصابع يدي ...   \n",
      "1492                    Right Eye twitching for 3 weeks   \n",
      "\n",
      "                                          english_words  \n",
      "40                                           [Tawuniya]  \n",
      "49                                           [Tawuniya]  \n",
      "51                                           [voltfast]  \n",
      "76                                           [Tawuniya]  \n",
      "92                                            [spacing]  \n",
      "117                                             [crown]  \n",
      "145                                          [Tawuniya]  \n",
      "197                                               [OCT]  \n",
      "275                                             [Nurax]  \n",
      "286                                 [complex, apthosis]  \n",
      "346                                          [Tawuniya]  \n",
      "360                                          [Tawuniya]  \n",
      "428                                          [Tawuniya]  \n",
      "448                                                [iq]  \n",
      "472                                        [Depression]  \n",
      "535                                          [Tawuniya]  \n",
      "605                                          [Tawuniya]  \n",
      "607                                          [Tawuniya]  \n",
      "626      [Deep, scaling, and, root, planing, open, gum]  \n",
      "646                                          [Tawuniya]  \n",
      "655                                          [Tawuniya]  \n",
      "676                                          [Tawuniya]  \n",
      "697                                         [c-peptide]  \n",
      "701                                          [Tawuniya]  \n",
      "728                                          [Tawuniya]  \n",
      "734                                             [Dewax]  \n",
      "787                                             [Dimra]  \n",
      "828                                          [antabuse]  \n",
      "860                                          [Tawuniya]  \n",
      "875                                          [Tawuniya]  \n",
      "918                   [Ulnar, nerve, sublaxatio, ulnar]  \n",
      "972                                          [Tawuniya]  \n",
      "1005  [yrs, old, was, diagnose, with, years, ago, ha...  \n",
      "1039                                       [free, move]  \n",
      "1086                                  [schizoaffective]  \n",
      "1088                                             [tsal]  \n",
      "1188                                         [Tawuniya]  \n",
      "1242                                           [liopic]  \n",
      "1277                                            [ridon]  \n",
      "1316                                         [Tawuniya]  \n",
      "1350                                         [Tawuniya]  \n",
      "1358                                              [ECG]  \n",
      "1390                                         [Tawuniya]  \n",
      "1399                          [dexamethasone, cymbalta]  \n",
      "1436                                         [Tawuniya]  \n",
      "1443                                         [Tawuniya]  \n",
      "1465                                         [Tawuniya]  \n",
      "1473                                         [primalan]  \n",
      "1483                                         [Tawuniya]  \n",
      "1492                [Right, Eye, twitching, for, weeks]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/1210448247.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['english_words'] = df['question_body'].apply(extract_english_words_better)\n"
     ]
    }
   ],
   "source": [
    "# Function to extract English words from text\n",
    "def extract_english_words_better(text):\n",
    "    # Remove most punctuation (except dash and slash)\n",
    "    text = re.sub(rf\"[{re.escape(string.punctuation.replace('-', '').replace('/', ''))}]\", \" \", text)\n",
    "\n",
    "    # Extract candidate words that are mostly A-Z or a-z\n",
    "    words = re.findall(r'\\b[A-Za-z][A-Za-z\\-\\/]{1,}\\b', text)\n",
    "\n",
    "    # Filter out all-numeric or very short items\n",
    "    filtered = [w for w in words if not w.lower().isdigit() and len(w) > 1]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "df['english_words'] = df['question_body'].apply(extract_english_words_better)\n",
    "\n",
    "# Show rows with extracted English\n",
    "df_with_english = df[df['english_words'].apply(len) > 0]\n",
    "print(df_with_english[['question_body', 'english_words']].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3382359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted English words: 6043\n",
      "Unique English words: 2176\n"
     ]
    }
   ],
   "source": [
    "all_english_words = list(chain.from_iterable(df['english_words']))\n",
    "print(f\"Total extracted English words: {len(all_english_words)}\")\n",
    "print(f\"Unique English words: {len(set(all_english_words))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b52ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tawuniya', 1987), ('the', 66), ('of', 63), ('and', 58), ('mg', 57), ('mri', 42), ('in', 40), ('to', 37), ('adhd', 35), ('pain', 34), ('my', 34), ('is', 33), ('for', 32), ('with', 30), ('consultation', 28), ('doctor', 27), ('have', 24), ('it', 24), ('eye', 23), ('from', 20), ('cyl', 19), ('mild', 16), ('prk', 16), ('crp', 14), ('medial', 14), ('no', 13), ('cdm', 13), ('expert', 13), ('af', 13), ('axis', 13), ('knee', 13), ('posterior', 13), ('left', 13), ('teeth', 13), ('counselling', 12), ('sph', 12), ('joint', 12), ('am', 12), ('tsh', 12), ('but', 11), ('me', 11), ('cbc', 11), ('right', 10), ('disc', 10), ('xr', 10), ('on', 9), ('general', 9), ('taa', 9), ('changes', 9), ('can', 9), ('back', 9), ('cervical', 9), ('systane', 9), ('hiv', 9), ('horn', 9), ('tear', 9), ('years', 8), ('weeks', 8), ('signal', 8), ('normal', 8), ('lumbar', 8), ('x-ray', 8), ('acl', 8), ('meniscus', 8), ('lower', 8), ('ml', 8), ('at', 8), ('esr', 8), ('days', 8), ('prozac', 8), ('gel', 8), ('get', 7), ('what', 7), ('be', 7), ('press', 7), ('degenerative', 7), ('not', 7), ('ultra', 7), ('cipralex', 7), ('need', 7), ('or', 7), ('was', 6), ('had', 6), ('drops', 6), ('bmi', 6), ('lustral', 6), ('dm', 6), ('type', 6), ('tobradex', 6), ('plus', 6), ('tooth', 6), ('red', 6), ('that', 6), ('injury', 6), ('tears', 6), ('anterior', 6), ('months', 6), ('now', 6), ('this', 6), ('please', 6), ('ray', 6), ('old', 5), ('ago', 5), ('free', 5), ('small', 5), ('like', 5), ('xray', 5), ('severe', 5), ('side', 5), ('possible', 5), ('out', 5), ('scoliosis', 5), ('suffering', 5), ('eyelid', 5), ('fml', 5), ('up', 5), ('fracture', 5), ('slim', 5), ('you', 5), ('ab', 5), ('aa', 5), ('refresh', 5), ('due', 5), ('only', 5), ('last', 5), ('ct', 5), ('sprain', 5), ('ligament', 5), ('time', 5), ('effusion', 5), ('about', 5), ('which', 5), ('minimal', 5), ('been', 5), ('ankle', 5), ('molar', 5), ('multi', 5), ('foot', 5), ('crown', 4), ('root', 4), ('open', 4), ('ulnar', 4), ('move', 4), ('ecg', 4), ('wis', 4), ('hello', 4), ('add', 4), ('cm', 4), ('curve', 4), ('low', 4), ('since', 4), ('there', 4), ('stye', 4), ('use', 4), ('if', 4), ('kg', 4), ('over', 4), ('vitamin', 4), ('dr', 4), ('muscle', 4), ('ii', 4), ('session', 4), ('artelac', 4), ('sph-', 4), ('fucithalmic', 4), ('ud', 4), ('fast', 4), ('redness', 4), ('eyes', 4), ('too', 4), ('dexa', 4), ('having', 4), ('spine', 4), ('when', 4), ('hi', 4), ('sir', 4), ('tobrex', 4), ('bench', 4), ('issue', 4), ('guard', 4), ('infection', 4), ('disorder', 4), ('dorsal', 4), ('marginal', 4), ('alphintern', 4), ('pcr', 4), ('rna', 4), ('night', 4), ('asthma', 4), ('inbody', 4), ('lesion', 4), ('seen', 4), ('got', 4), ('go', 4), ('feel', 4), ('while', 4), ('upper', 4), ('maxitrol', 4), ('lateral', 4), ('once', 4), ('oct', 3), ('gum', 3), ('dimra', 3), ('bad', 3), ('mood', 3), ('much', 3), ('leg', 3), ('would', 3), ('pco', 3), ('lordotic', 3), ('stage', 3), ('help', 3), ('spondylosis', 3), ('as', 3), ('vigamox', 3), ('lexotanil', 3), ('relaxon', 3), ('quetiapine', 3), ('straightened', 3), ('spondylotic', 3), ('spondylodegenerative', 3), ('minded', 3), ('cyst', 3), ('creatine', 3), ('push', 3), ('bulge', 3), ('neural', 3), ('zelax', 3), ('neck', 3), ('sr', 3), ('complete', 3), ('acid', 3), ('arcoxia', 3), ('ldl', 3), ('optidex', 3), ('high', 3), ('examination', 3), ('technique', 3), ('torn', 3), ('femoral', 3), ('irritation', 3), ('are', 3), ('before', 3), ('dental', 3), ('thanks', 3), ('scan', 3), ('painful', 3), ('after', 3), ('hours', 3), ('lordosis', 3), ('do', 3), ('shoulder', 3), ('collateral', 3), ('victoza', 3), ('test', 3), ('fsh', 3), ('lh', 3), ('tendon', 3), ('focal', 3), ('trigger', 3), ('finger', 3), ('chronic', 3), ('amitriptyline', 3), ('reduced', 3), ('bright', 3), ('discs', 3), ('osteophytosis', 3), ('coxicel', 3), ('valgus', 3), ('ulna', 3), ('escitalopram', 3), ('ozempic', 3), ('bronchial', 3), ('wellbutrin', 3), ('htn', 3), ('both', 3), ('alpha', 3), ('middle', 3), ('mm', 3), ('around', 3), ('did', 3), ('cr', 3), ('spot', 3), ('brace', 3), ('escitam', 3), ('fresh', 3), ('first', 3), ('rct', 3), ('same', 3), ('mucoid', 3), ('problem', 3), ('surgery', 3), ('ambezim', 3), ('started', 3), ('hyfresh', 3), ('swollen', 3), ('visitor', 3), ('navigated', 3), ('again', 3), ('sleep', 3), ('fixing', 3), ('xanax', 3), ('walking', 3), ('sequit', 3), ('rybelsus', 3), ('drop', 3), ('la', 3), ('je', 3), ('ignore', 3), ('vismed', 3), ('depression', 2), ('planing', 2), ('nerve', 2), ('yrs', 2), ('whenever', 2), ('attack', 2), ('ridon', 2), ('dexamethasone', 2), ('cymbalta', 2), ('white', 2), ('likely', 2), ('lorazepam', 2), ('using', 2), ('buspirone', 2), ('safe', 2), ('mirtazapine', 2), ('insomnia', 2), ('part', 2), ('msm', 2), ('vit', 2), ('straightening', 2), ('multilevel', 2), ('noted', 2), ('narrowing', 2), ('space', 2), ('may', 2), ('hospital', 2), ('al', 2), ('ae', 2), ('papilledema', 2), ('head', 2), ('by', 2), ('arginine', 2), ('vd', 2), ('prescription', 2), ('stock', 2), ('all', 2), ('muscular', 2), ('st', 2), ('john', 2), ('wort', 2), ('her', 2), ('week', 2), ('tobramycin', 2), ('should', 2), ('question', 2), ('new', 2), ('narrowed', 2), ('female', 2), ('fluca', 2), ('regimax', 2), ('chromax', 2), ('klavox', 2), ('capsules', 2), ('diffuse', 2), ('significant', 2), ('its', 2), ('age', 2), ('ginkgo', 2), ('biloba', 2), ('quitapex', 2), ('bpd', 2), ('green', 2), ('bean', 2), ('mograflox', 2), ('hymox', 2), ('ck', 2), ('mr', 2), ('sagittal', 2), ('axial', 2), ('findings', 2), ('salipax', 2), ('centeral', 2), ('protrusion', 2), ('amoclan', 2), ('apigen', 2), ('ginseng', 2), ('kianpi', 2), ('pil', 2), ('know', 2), ('gym', 2), ('current', 2), ('ssri', 2), ('fibula', 2), ('front', 2), ('laptop', 2), ('take', 2), ('vexal', 2), ('advice', 2), ('body', 2), ('less', 2), ('saxenda', 2), ('bleeding', 2), ('tennis', 2), ('arch', 2), ('celebrex', 2), ('vizols', 2), ('besucher', 2), ('hat', 2), ('timolol', 2), ('tablets', 2), ('power', 2), ('psmf', 2), ('ptk', 2), ('clinical', 2), ('multiplanar', 2), ('ulcer', 2), ('grade', 2), ('a-k', 2), ('icl', 2), ('thyroid', 2), ('trium', 2), ('positive', 2), ('cyl-', 2), ('guru', 2), ('anti', 2), ('terramycin', 2), ('clavicle', 2), ('hallux', 2), ('euthyrox', 2), ('diamet', 2), ('soon', 2), ('forxiga', 2), ('cbd', 2), ('calm', 2), ('see', 2), ('cuff', 2), ('tymer', 2), ('forte', 2), ('risperidone', 2), ('alcon', 2), ('associated', 2), ('glucomannan', 2), ('naproxen', 2), ('com', 2), ('bicep', 2), ('more', 2), ('than', 2), ('tm', 2), ('morning', 2), ('an', 2), ('down', 2), ('seroquel', 2), ('hand', 2), ('black', 2), ('wrist', 2), ('iv', 2), ('rt', 2), ('puss', 2), ('bilateral', 2), ('disk', 2), ('cyclopentolate', 2), ('igg', 2), ('igm', 2), ('anazol', 2), ('cruciate', 2), ('wisdom', 2), ('jaw', 2), ('want', 2), ('vision', 2), ('gad', 2), ('novorapid', 2), ('lymphocytes', 2), ('neutrophils', 2), ('mirzagen', 2), ('bite', 2), ('paroxat', 2), ('centrum', 2), ('wash', 2), ('talus', 2), ('relative', 2), ('so', 2), ('well', 2), ('adazio', 2), ('topradex', 2), ('hypertension', 2), ('sayed', 2), ('past', 2), ('ask', 2), ('inner', 2), ('think', 2), ('remeron', 2), ('feeling', 2), ('ultrasound', 2), ('distal', 2), ('vizol', 2), ('asot', 2), ('evidence', 2), ('condyle', 2), ('long', 2), ('could', 2), ('zyprexa', 2), ('metformin', 2), ('megamox', 2), ('invisalign', 2), ('ac', 2), ('pranza', 2), ('blood', 2), ('results', 2), ('fasting', 2), ('soft', 2), ('ointment', 2), ('getting', 2), ('de', 2), ('pas', 2), ('panic', 2), ('growth', 2), ('food', 2), ('team', 2), ('attached', 2), ('altibbi', 2), ('naturale', 2), ('hormone', 2), ('pharma', 2), ('degeneration', 2), ('very', 2), ('partial', 2), ('ch', 2), ('walk', 2), ('standing', 2), ('tegretol', 2), ('co', 2), ('fat', 2), ('citalopram', 2), ('diclomax', 2), ('graves', 2), ('disease', 2), ('hylo', 2), ('vw', 2), ('zoloft', 2), ('activities', 2), ('daily', 2), ('advanced', 2), ('ipd', 2), ('area', 2), ('voltfast', 1), ('spacing', 1), ('nurax', 1), ('complex', 1), ('apthosis', 1), ('iq', 1), ('deep', 1), ('scaling', 1), ('c-peptide', 1), ('dewax', 1), ('antabuse', 1), ('sublaxatio', 1), ('diagnose', 1), ('swings', 1), ('angry', 1), ('anyone', 1), ('might', 1), ('reason', 1), ('schizoaffective', 1), ('tsal', 1), ('liopic', 1), ('primalan', 1), ('twitching', 1), ('otc', 1), ('opinion', 1), ('recent', 1), ('infarcts', 1), ('few', 1), ('foci', 1), ('abnormal', 1), ('cerebral', 1), ('matter', 1), ('nonspecific', 1), ('vasculopathic', 1), ('les', 1), ('triactin', 1), ('modax', 1), ('remowax', 1), ('decrease', 1), ('lymphocyte', 1), ('platelet', 1), ('count', 1), ('rbcs', 1), ('wbcs', 1), ('beta', 1), ('cell', 1), ('function', 1), ('burning', 1), ('itchy', 1), ('pirox', 1), ('acetaazolmda', 1), ('psychiatrist', 1), ('vortioxetine', 1), ('occipital', 1), ('omacilln', 1), ('fitty', 1), ('dent', 1), ('almaali', 1), ('hafar', 1), ('batin', 1), ('result', 1), ('home', 1), ('meds', 1), ('given', 1), ('relieved', 1), ('elevated', 1), ('headaches', 1), ('quit', 1), ('diamox', 1), ('order', 1), ('cure', 1), ('eylox', 1), ('sertralin', 1), ('enerzad', 1), ('somatropin', 1), ('ssss', 1), ('lesions', 1), ('describe', 1), ('optilubric', 1), ('pharmacies', 1), ('another', 1), ('alternative', 1), ('pregnant', 1), ('pregnancy', 1), ('havee', 1), ('oint', 1), ('them', 1), ('guide', 1), ('lortin', 1), ('haloperidol', 1), ('spondylolithesis', 1), ('spaces', 1), ('mewing', 1), ('early', 1), ('depojoy', 1), ('wbc', 1), ('plt', 1), ('neut', 1), ('cobm', 1), ('ganglion', 1), ('amoxicillin', 1), ('clavulanic', 1), ('ngs', 1), ('patella', 1), ('genuphil', 1), ('advance', 1), ('harva', 1), ('gold', 1), ('pet/ct', 1), ('dynewell', 1), ('hire', 1), ('kine', 1), ('pregabalin', 1), ('fucidin', 1), ('compromise', 1), ('significance', 1), ('clinically', 1), ('correlated', 1), ('easy', 1), ('roxil', 1), ('voltic', 1), ('optifresh', 1), ('pvns', 1), ('ecitalopram', 1), ('alperid', 1), ('larcodic', 1), ('almag', 1), ('milatonin', 1), ('sgpt', 1), ('tsh-', 1), ('hassan', 1), ('adel', 1), ('altambakti', 1), ('dw', 1), ('sdu', 1), ('alcohol', 1), ('abuse', 1), ('colircusi', 1), ('zetrafenac', 1), ('axi', 1), ('airpiprazole', 1), ('estlipram', 1), ('colnzepam', 1), ('clonzepam', 1), ('crunches', 1), ('miacalcic', 1), ('simbrinza', 1), ('travatan', 1), ('amirtriptyline', 1), ('urice', 1), ('glivec', 1), ('korandil', 1), ('express', 1), ('olopat', 1), ('collure', 1), ('bleu', 1), ('lg', 1), ('coffee', 1), ('extract', 1), ('raspberry', 1), ('ketones', 1), ('kidney', 1), ('tea', 1), ('standar', 1), ('virustat', 1), ('km', 1), ('active', 1), ('swixolate', 1), ('feeritin', 1), ('optifucin', 1), ('cholesterol', 1), ('elquis', 1), ('phpv', 1), ('mama', 1), ('collagen', 1), ('extra', 1), ('cipra', 1), ('pro', 1), ('intestine', 1), ('resection', 1), ('vitalife', 1), ('cal', 1), ('cium', 1), ('misophonia', 1), ('specialist', 1), ('symptoms', 1), ('ocd', 1), ('pku', 1), ('avn', 1), ('mms', 1), ('bodybuild', 1), ('index', 1), ('brachydactyly', 1), ('liquigel', 1), ('relestat', 1), ('tl', 1), ('coronal', 1), ('stir', 1), ('attach', 1), ('optest', 1), ('consultant', 1), ('dry', 1), ('weather', 1), ('allergy', 1), ('wide', 1), ('based', 1), ('clindamycin', 1), ('bd', 1), ('swallowing', 1), ('centrum-', 1), ('mycool', 1), ('declac', 1), ('melatonin', 1), ('month', 1), ('tests', 1), ('taken', 1), ('going', 1), ('health', 1), ('condition', 1), ('dexaflox', 1), ('privacond', 1), ('nodep', 1), ('serum', 1), ('creatinine', 1), ('does', 1), ('heal', 1), ('related', 1), ('replacement', 1), ('artificial', 1), ('emotional', 1), ('putbursts', 1), ('hidrocil', 1), ('filac', 1), ('vega', 1), ('excessive', 1), ('nature', 1), ('job', 1), ('such', 1), ('nearly', 1), ('bca', 1), ('enalapril', 1), ('everyday', 1), ('prl', 1), ('torticollis', 1), ('convexity', 1), ('preserved', 1), ('gyrex', 1), ('buvidal', 1), ('lu', 1), ('viitamin', 1), ('paraxone', 1), ('augmeniten', 1), ('flagyl', 1), ('fiber', 1), ('lying-distal', 1), ('depovit', 1), ('retreatment', 1), ('nasal', 1), ('tube', 1), ('butrans', 1), ('fffffffffffffffffffffffffffff', 1), ('thiozac', 1), ('omega', 1), ('benox', 1), ('hylo-comod', 1), ('depressed', 1), ('increasing', 1), ('tailbone', 1), ('mainly', 1), ('sitting', 1), ('posture', 1), ('adjustments', 1), ('haven', 1), ('helped', 1), ('seeking', 1), ('rips', 1), ('also', 1), ('between', 1), ('lung', 1), ('stomach', 1), ('weakness', 1), ('hr', 1), ('hypothyroidism', 1), ('tiny', 1), ('schmorl', 1), ('nodes', 1), ('bursitis', 1), ('gentiomycin', 1), ('solu', 1), ('medrol', 1), ('contusio', 1), ('sone', 1), ('metfor', 1), ('jcaer', 1), ('indicardin', 1), ('diplopia', 1), ('formo', 1), ('line', 1), ('reserve', 1), ('crunch', 1), ('busbirone', 1), ('incline', 1), ('fly', 1), ('stevia', 1), ('sweet', 1), ('amitrptylin', 1), ('tylenol', 1), ('jorvit', 1), ('ciprofloxacin', 1), ('tabiflex', 1), ('clopixol', 1), ('pharmaton', 1), ('syrup', 1), ('citoxal', 1), ('headache', 1), ('rubeosis', 1), ('iridis', 1), ('profen', 1), ('conventin', 1), ('vitamine', 1), ('arox', 1), ('information', 1), ('multisequence', 1), ('performed', 1), ('proximal', 1), ('attachment', 1), ('patellar', 1), ('thickened', 1), ('displays', 1), ('intermediate', 1), ('powder', 1), ('rhinosinusitos', 1), ('tonsilitis', 1), ('otitis', 1), ('externa', 1), ('gingivitis', 1), ('gingival', 1), ('vitd', 1), ('augmenten', 1), ('cefuxrim', 1), ('tavanic', 1), ('brintellix', 1), ('chlorpromazine', 1), ('pdf', 1), ('hyaluronic', 1), ('fluoxetine', 1), ('custom', 1), ('lasik', 1), ('supraspinatous', 1), ('morphology', 1), ('osteoplytes', 1), ('mgo', 1), ('zinoximor', 1), ('histamine', 1), ('snri', 1), ('avascular', 1), ('necrosis', 1), ('flumox', 1), ('valpam', 1), ('dear', 1), ('anxiety/depression', 1), ('reduce', 1), ('worried', 1), ('withdrawal', 1), ('manage', 1), ('safely', 1), ('refill', 1), ('xx', 1), ('xxy', 1), ('milga', 1), ('bov', 1), ('liquid', 1), ('reparil', 1), ('zinoximoe', 1), ('brufen', 1), ('dzrt', 1), ('surgam', 1), ('reyebluss', 1), ('investigated', 1), ('shows', 1), ('degenerated', 1), ('phlm', 1), ('next', 1), ('step', 1), ('argivit', 1), ('gelnoid', 1), ('labrum', 1), ('glenhomeral', 1), ('subcoracoid', 1), ('bursits', 1), ('daktarin', 1), ('klavunta', 1), ('bid', 1), ('chiropractor', 1), ('vascular', 1), ('rotator', 1), ('oaeous', 1), ('texture', 1), ('veterbal', 1), ('bodies', 1), ('pred', 1), ('wi', 1), ('dentagyl', 1), ('looking', 1), ('telemedicine', 1), ('explain', 1), ('price', 1), ('methycobal', 1), ('stalevo', 1), ('sun', 1), ('dat', 1), ('complain', 1), ('numbness', 1), ('limbs', 1), ('half', 1), ('legs', 1), ('aggravated', 1), ('wa', 1), ('glaucoma', 1), ('xolamol', 1), ('blinkgel', 1), ('volvlaxt', 1), ('dexol', 1), ('geopota-', 1), ('spineis', 1), ('anatomic', 1), ('osteocare', 1), ('apha', 1), ('tratul', 1), ('cy', 1), ('osteochondral', 1), ('talar', 1), ('dome', 1), ('measuring', 1), ('underlying', 1), ('marrow', 1), ('edema', 1), ('splits', 1), ('strep', 1), ('adenovirus', 1), ('mirtmash', 1), ('basilaljneibi', 1), ('gmail', 1), ('zwei', 1), ('hulax', 1), ('corotrope', 1), ('sydney', 1), ('arm', 1), ('hurting', 1), ('pandol', 1), ('nicotine', 1), ('pouch', 1), ('prof', 1), ('remember', 1), ('bumping', 1), ('twisting', 1), ('ciprocin', 1), ('edenorm', 1), ('panadol', 1), ('erastapex', 1), ('netralix', 1), ('dogmatil', 1), ('seroxat', 1), ('dsdsadsada', 1), ('extreme', 1), ('anxiety', 1), ('moment', 1), ('took', 1), ('buspar', 1), ('each', 1), ('nothing', 1), ('anxiolytic', 1), ('works', 1), ('will', 1), ('divorce', 1), ('don', 1), ('tracking', 1), ('lipoma', 1), ('cp', 1), ('stabilisation', 1), ('phsychologist', 1), ('reparil-dragees', 1), ('chondromalacia', 1), ('hgh', 1), ('gct', 1), ('prothiazine', 1), ('hosam', 1), ('samara', 1), ('oximal', 1), ('damest', 1), ('thave', 1), ('plastic', 1), ('splinter', 1), ('stuck', 1), ('making', 1), ('numb', 1), ('moving', 1), ('hydoxy', 1), ('ganvir', 1), ('nimelide', 1), ('covid', 1), ('croma', 1), ('flupentixol', 1), ('melitracen', 1), ('orthofix', 1), ('tusskan', 1), ('spirazol', 1), ('big', 1), ('toe', 1), ('xilioal', 1), ('phenylmadrin', 1), ('eso', 1), ('romeron', 1), ('lose', 1), ('raidon', 1), ('coloboma', 1), ('range', 1), ('ft', 1), ('centromedullary', 1), ('nailing', 1), ('malleolus', 1), ('second', 1), ('under', 1), ('dentist', 1), ('says', 1), ('abscess', 1), ('she', 1), ('still', 1), ('slight', 1), ('hitting', 1), ('these', 1), ('areas', 1), ('provironic', 1), ('credanil', 1), ('history', 1), ('augmentin', 1), ('amoxicilin', 1), ('didn', 1), ('rnfl', 1), ('horizontal', 1), ('cup', 1), ('ratio', 1), ('paroxetine', 1), ('hydrochloride', 1), ('allergan', 1), ('flam', 1), ('avoidant', 1), ('personality', 1), ('votre', 1), ('omeprazole', 1), ('diagnosis', 1), ('online', 1), ('nervacine', 1), ('gh', 1), ('methylphenidate', 1), ('opticyclin', 1), ('phq-', 1), ('r-', 1), ('distant', 1), ('near', 1), ('zdfzdfczsddzsd', 1), ('vvvvvvvvvvvvvvvv', 1), ('deltoid', 1), ('hd', 1), ('nidazole', 1), ('konadole', 1), ('bitter', 1), ('melon', 1), ('acai', 1), ('berry', 1), ('marnys', 1), ('royal', 1), ('jelly', 1), ('anterrior', 1), ('degneration', 1), ('relax', 1), ('lyrica', 1), ('halosenation', 1), ('hlv', 1), ('xxx', 1), ('lacoma', 1), ('brimogan', 1), ('customer', 1), ('service', 1), ('kinase', 1), ('total', 1), ('dulophi', 1), ('laroxyl', 1), ('provide', 1), ('theraby', 1), ('sessions', 1), ('amigen', 1), ('seralin', 1), ('lexopam', 1), ('depzabid', 1), ('conjunctiva', 1), ('looks', 1), ('pulled', 1), ('shoulder/hand', 1), ('where', 1), ('khobar', 1), ('accommodation', 1), ('lazer', 1), ('correct', 1), ('advise', 1), ('cidophaga', 1), ('tobrin', 1), ('reprise', 1), ('moveasy', 1), ('virax', 1), ('mdd', 1), ('erecta', 1), ('mark', 1), ('degludec', 1), ('insulin', 1), ('lantus', 1), ('levamir', 1), ('apcycline', 1), ('aftame', 1), ('dolo', 1), ('cyclosprine', 1), ('fluoron', 1), ('liposic', 1), ('claritine', 1), ('ciprelx', 1), ('listrene', 1), ('oral', 1), ('nil', 1), ('fastflam', 1), ('roxonin', 1), ('furofen', 1), ('inside', 1), ('thursday', 1), ('yesterday', 1), ('swelling', 1), ('smoking', 1), ('married', 1), ('insect', 1), ('curvature', 1), ('maintained', 1), ('bony', 1), ('aligenment', 1), ('ar', 1), ('orthopedic', 1), ('timolol/ciprocin', 1), ('nopain', 1), ('ancle', 1), ('toxic', 1), ('airtal', 1), ('flogeril', 1), ('reparil-gel', 1), ('buion', 1), ('trillerg', 1), ('silver', 1), ('latte', 1), ('zenon', 1), ('enhance', 1), ('roller', 1), ('dorsiflexion', 1), ('suber', 1), ('trim', 1), ('lymphocytosis', 1), ('monocytosis', 1), ('absolute', 1), ('neutropenia', 1), ('monocytes', 1), ('tprk', 1), ('anafranil', 1), ('inclusion', 1), ('ad', 1), ('gerd', 1), ('vectoza', 1), ('forteo', 1), ('madam', 1), ('accident', 1), ('room', 1), ('lost', 1), ('other', 1), ('possession', 1), ('covers', 1), ('insurance', 1), ('bdd', 1), ('eyelids', 1), ('ahdh', 1), ('arpenia', 1), ('pakistan', 1), ('recommends', 1), ('reconstruction', 1), ('public', 1), ('speaking', 1), ('glim', 1), ('gliptmet', 1), ('orotix', 1), ('roxonine', 1), ('tobradox', 1), ('refreshment', 1), ('benzodiazepines', 1), ('masturbation', 1), ('fetishism', 1), ('curam', 1), ('bade', 1), ('shi', 1), ('aan', 1), ('asnan', 1), ('bristol', 1), ('ltd', 1), ('anconeus', 1), ('protopic', 1), ('x-', 1), ('canal', 1), ('procedure', 1), ('done', 1), ('infected', 1), ('doctors', 1), ('suggested', 1), ('extraction', 1), ('klrk', 1), ('systan', 1), ('name', 1), ('mahmoud', 1), ('patient', 1), ('id', 1), ('date', 1), ('gre', 1), ('einding', 1), ('antiimflamatory', 1), ('augmantiene', 1), ('plantar', 1), ('fasciitis', 1), ('naphcon', 1), ('tablet', 1), ('closing', 1), ('coil', 1), ('spirng', 1), ('taskine', 1), ('rheumagel', 1), ('parafon', 1), ('jointace', 1), ('estikan', 1), ('gentacin', 1), ('elbow', 1), ('ve', 1), ('experiencing', 1), ('issues', 1), ('wake', 1), ('every', 1), ('hour', 1), ('shor', 1), ('dexatrol', 1), ('corner', 1), ('sudafed', 1), ('eosinophil', 1), ('zz', 1), ('splint', 1), ('medam', 1), ('temparey', 1), ('he', 1), ('coming', 1), ('loction', 1), ('check', 1), ('shock', 1), ('wave', 1), ('tendinosis', 1), ('common', 1), ('flexor', 1), ('tendons', 1), ('how', 1), ('jan', 1), ('amh', 1), ('saridon', 1), ('brk', 1), ('anuva', 1), ('gotavex', 1), ('blegica', 1), ('mydriacyl', 1), ('zolpidem', 1), ('doing', 1), ('overhead', 1), ('hurt', 1), ('self', 1), ('stiff', 1), ('nick', 1), ('shoulders', 1), ('similar', 1), ('cleron', 1), ('clarithromycin', 1), ('blowing', 1), ('dust', 1), ('printing', 1), ('machines', 1), ('persistent', 1), ('some', 1), ('soasmolyt', 1), ('thinking', 1), ('osgood', 1), ('shlatters', 1), ('rapidus', 1), ('nsaid', 1), ('nsaidn', 1), ('radius', 1), ('toplexil', 1), ('valuim', 1), ('lorvast', 1), ('moov', 1), ('maxidex', 1), ('follow', 1), ('dec', 1), ('huge', 1), ('sides', 1), ('sciatica', 1), ('optilone', 1), ('ect', 1), ('falm', 1), ('isopto', 1), ('gums', 1), ('because', 1), ('toothe', 1), ('dont', 1), ('smoke', 1), ('prescribe', 1), ('antibiotic', 1), ('catafast', 1), ('allergic', 1), ('levox', 1), ('levofloxaacin', 1), ('called', 1), ('loraz', 1), ('egypro', 1), ('finistil', 1), ('snris', 1), ('oflox', 1), ('premolars', 1), ('chain', 1), ('exam', 1), ('cystic', 1), ('inferior', 1), ('paterllar', 1), ('retinaculum', 1), ('pth', 1), ('hurts', 1), ('prevents', 1), ('distance', 1), ('wearing', 1), ('heels', 1), ('gets', 1), ('cheek', 1), ('filled', 1), ('everytime', 1), ('eat', 1), ('benzaflex', 1), ('aripal', 1), ('kemadrine', 1), ('risdone', 1), ('heel', 1), ('physically', 1), ('noticeable', 1), ('signs', 1), ('just', 1), ('needle', 1), ('piercing', 1), ('kind', 1), ('worsens', 1), ('clucophage', 1), ('saphenou', 1), ('katafast', 1), ('cefixime', 1), ('ibruofen', 1), ('conclusion', 1), ('compression', 1), ('exiting', 1), ('giant', 1), ('verte', 1), ('annular', 1), ('relaxation', 1), ('correlation', 1), ('declophen', 1), ('said', 1), ('bump', 1), ('drink', 1), ('water', 1), ('plz', 1), ('concerned', 1), ('thankfully', 1), ('thickness', 1), ('pelvic', 1), ('tilt', 1), ('submandible', 1), ('celecoxib', 1), ('cipram', 1), ('ers', 1), ('forever', 1), ('bee', 1), ('pollen', 1), ('zoril', 1), ('pass', 1), ('confort', 1), ('zone', 1), ('orchapred', 1), ('refrech', 1), ('cholestrol', 1), ('triglecerides', 1), ('hdl', 1), ('sugar', 1), ('lotofolone', 1), ('oragel', 1), ('propolsfast', 1), ('rufenal', 1), ('cracks', 1), ('ciprlex', 1), ('careprost', 1), ('staphylococcus', 1), ('aureus', 1), ('ms', 1), ('sever', 1), ('day', 1), ('movemnet', 1), ('touching', 1), ('sweling', 1), ('hx', 1), ('trauma', 1), ('paraspinal', 1), ('tissue', 1), ('shadow', 1), ('lab', 1), ('points', 1), ('triceps', 1), ('tobrason', 1), ('chalazion', 1), ('cataflam', 1), ('xylocaine', 1), ('tricuspid', 1), ('valvenormal', 1), ('valve', 1), ('trivial', 1), ('regurgitation', 1), ('ph', 1), ('ed', 1), ('uppp', 1), ('fatzorb', 1), ('external', 1), ('rotation', 1), ('abduction', 1), ('above', 1), ('degrees', 1), ('olanzapin', 1), ('prednisolone', 1), ('stretch', 1), ('xnax', 1), ('escitalax', 1), ('suspetion', 1), ('nondisplaced', 1), ('crestor', 1), ('ssssss', 1), ('most', 1), ('cationorm', 1), ('procyclidine', 1), ('propranolol', 1), ('rofenac', 1), ('snowflower', 1), ('aaaaaaaaaaaaaaaaaaaaaaa', 1), ('retromoral', 1), ('trigone', 1), ('turk', 1), ('ty', 1), ('lorezepam', 1), ('blu', 1), ('um', 1), ('dentail', 1), ('paning', 1), ('year', 1), ('paining', 1), ('minescal', 1), ('grinding', 1), ('suitable', 1), ('discoid', 1), ('tobrabex', 1), ('cold', 1), ('gett', 1), ('better', 1), ('entapro', 1), ('faverin', 1), ('bonsoir', 1), ('jai', 1), ('un', 1), ('propos', 1), ('lhygiene', 1), ('ca', 1), ('concerne', 1), ('juste', 1), ('facon', 1), ('genre', 1), ('quand', 1), ('nettoie', 1), ('le', 1), ('visage', 1), ('dis', 1), ('dans', 1), ('ma', 1), ('tete', 1), ('correcte', 1), ('ce', 1), ('que', 1), ('fais', 1), ('et', 1), ('apres', 1), ('elle', 1), ('plait', 1), ('ups', 1), ('systans', 1), ('ths', 1), ('formula', 1), ('cmv', 1), ('tobredex', 1), ('vismid', 1), ('drip', 1), ('pmdd', 1), ('hsb', 1), ('print', 1), ('vitamax', 1), ('achilles', 1), ('phlebitis', 1), ('exotique', 1), ('sexovit', 1), ('relezin', 1), ('rivotril', 1), ('clonotril', 1), ('proviron', 1), ('aneurysmal', 1), ('bone', 1), ('july', 1), ('talo', 1), ('fibular', 1), ('pnumatik', 1), ('walker', 1), ('nootropic', 1), ('piracetam', 1), ('carnitine', 1), ('poly', 1), ('aplefit', 1), ('librax', 1), ('electroophthalmia', 1), ('miliclav', 1), ('hyalfid', 1), ('hylo-gel', 1), ('antibody', 1), ('aclasta', 1), ('zoledonic', 1), ('fatlos', 1), ('borex', 1), ('inteputic', 1), ('english', 1), ('bisoprolol', 1), ('glimpride', 1), ('atorvastatin', 1), ('enalpril', 1), ('meteor', 1), ('three', 1), ('times', 1), ('keto', 1), ('lipo', 1), ('c-reactive', 1), ('protein', 1), ('cme', 1), ('macula', 1), ('reference', 1), ('request', 1), ('however', 1), ('connection', 1), ('disturbed', 1), ('talk', 1), ('extrauma', 1), ('dna', 1), ('greenstick', 1), ('cast', 1), ('composite', 1), ('sandwich', 1), ('technic', 1), ('enquire', 1), ('treatment', 1), ('required', 1), ('bottom', 1), ('photo', 1), ('adductor', 1), ('strain', 1), ('sports', 1), ('hernia', 1), ('denmark', 1), ('deka', 1), ('sustanon', 1), ('cerotone', 1), ('otocol', 1), ('convulex', 1), ('mlg/ml', 1), ('xl', 1), ('neurton', 1), ('arthri', 1), ('flex', 1), ('cc', 1), ('defocus', 1), ('rasonographic', 1), ('ealed', 1), ('mobic', 1), ('salvix', 1), ('chitosan', 1), ('capsule', 1), ('orly', 1), ('xtreme', 1), ('facing', 1), ('karting', 1), ('phmm', 1), ('bent', 1), ('cable', 1), ('row', 1), ('currently', 1), ('believe', 1), ('permanent', 1), ('genu', 1), ('varum', 1), ('hto', 1), ('uric', 1), ('brexin', 1), ('mentophor--lornoxicam', 1), ('zinc', 1), ('ost-care', 1), ('trolley', 1), ('city', 1), ('pigmentos', 1), ('google', 1), ('jonmera', 1), ('livostin', 1), ('crutches', 1), ('turns', 1), ('purple', 1), ('hikma', 1), ('bankert', 1), ('hillsach', 1), ('deanipyx', 1), ('xenical', 1), ('vi', 1), ('alt', 1), ('omega-', 1), ('heart', 1), ('beat', 1), ('postero-lateral', 1), ('level', 1), ('osteoarthritis', 1), ('ankylosing', 1), ('spond', 1), ('anafalm', 1), ('asperger', 1), ('dalacin', 1), ('flector', 1), ('hylo-', 1), ('dan', 1), ('couldn', 1), ('coz', 1), ('bmr', 1), ('percentage', 1), ('metabolic', 1), ('syndrome', 1), ('normo', 1), ('rears', 1), ('iwhite', 1), ('ipl', 1), ('discharge', 1), ('tobadex', 1), ('myopia', 1), ('jjjjj', 1), ('topography', 1), ('today', 1), ('cannot', 1), ('dimr', 1), ('traumatic', 1), ('following', 1), ('rupture', 1), ('metatarsoph', 1), ('primolut', 1), ('clofen', 1), ('azyn', 1), ('solo', 1), ('load', 1), ('tingling', 1), ('ld', 1), ('fluoxet', 1), ('proferti', 1), ('gentaserv', 1), ('cts', 1), ('tfcc', 1), ('tofranil-meteoxane-', 1), ('onlefit', 1), ('agout', 1), ('realx', 1), ('monohidrate', 1), ('xylocain', 1), ('omafen', 1), ('december', 1), ('solotick', 1), ('mra', 1), ('brain', 1), ('oxazepam', 1), ('neomercazole', 1), ('hyperthyrodism', 1), ('antihistamine', 1), ('fluoxeth', 1), ('pcv', 1), ('hp', 1), ('mch', 1), ('mchc', 1), ('bb', 1), ('venex', 1), ('suspected', 1), ('minor', 1), ('bursal', 1), ('surface', 1), ('supraspinatus', 1), ('resistance', 1), ('izzeddin', 1), ('ng/ml', 1), ('ui', 1), ('moodapex', 1), ('chat', 1), ('lina', 1), ('mandibilar', 1), ('attackke', 1), ('toradex', 1), ('discomfort', 1), ('knockle', 1), ('lots', 1), ('knees', 1), ('stairs', 1), ('appl', 1), ('cider', 1), ('vinegra', 1), ('bed', 1), ('spc', 1), ('avastine', 1), ('scanner', 1), ('hct', 1), ('extroma', 1), ('alphertern', 1), ('loss', 1), ('consistent', 1), ('spasm', 1), ('silomes', 1), ('reset', 1), ('exotropia', 1), ('comod', 1), ('testing', 1), ('flagyle', 1), ('listerine', 1), ('cool', 1), ('mint', 1), ('causing', 1), ('praying', 1), ('tibiaand', 1), ('solotic', 1), ('class', 1), ('missing', 1), ('mi', 1), ('image', 1), ('noticed', 1), ('appearance', 1), ('yellow', 1), ('tend', 1), ('cornea', 1), ('beside', 1), ('pupil', 1), ('phenomenon', 1), ('seroque', 1), ('rex-forte', 1), ('flazol', 1), ('scleral', 1), ('pre', 1), ('mildly', 1), ('foramina', 1), ('lorivana', 1), ('lorezpam', 1), ('prila', 1), ('amirol', 1), ('oradexon', 1), ('recovery', 1), ('surgeries', 1), ('fingers', 1), ('hands', 1), ('hcu', 1), ('femur', 1), ('oxandrolone', 1), ('uv', 1), ('ems', 1), ('uralyt', 1), ('efexor', 1), ('clicking', 1), ('increase', 1), ('hyperflexion', 1), ('affecting', 1), ('tried', 1), ('vo', 1), ('ckd', 1), ('calmtonin', 1), ('eyedrops', 1), ('burner', 1), ('super', 1), ('citrimax', 1), ('oxymetholone', 1), ('osteogenesis', 1), ('imperfecta', 1), ('serodase', 1), ('cliptol', 1), ('gil', 1), ('cefotriaxon', 1), ('ultrasysten', 1), ('zoom', 1), ('ceclor', 1), ('stresstabs', 1), ('nystatine', 1), ('daktarine', 1), ('ativan', 1), ('supplement', 1), ('maverney', 1), ('baby', 1), ('blue', 1), ('toixic', 1), ('psyhcosis', 1), ('nacl', 1), ('humerus', 1), ('flexion', 1), ('extension', 1), ('omacillin', 1), ('naphcon-a', 1), ('defined', 1), ('geographic', 1), ('hypoechoic', 1), ('segment', 1), ('fatty', 1), ('sparing', 1), ('sondos', 1), ('teeeest', 1), ('schizophrenia', 1), ('respirdol', 1), ('hallucinations', 1), ('flox', 1), ('louxtr', 1), ('cosopt', 1), ('cross', 1), ('hyalubrix', 1), ('medijel', 1), ('hyalu', 1), ('brix', 1), ('adult', 1), ('grippe', 1), ('fuolan', 1), ('mounjaro', 1), ('minirinmelt', 1), ('pg/ml', 1), ('sexual', 1), ('interest', 1), ('arrousal', 1), ('two', 1), ('children', 1), ('affectung', 1), ('marriage', 1), ('has', 1), ('happening', 1), ('yea', 1), ('toeing', 1), ('effuisson', 1), ('fluid', 1), ('surrounding', 1), ('peroneal', 1), ('tibialis', 1), ('tendens', 1), ('representing', 1), ('tenosynovitis', 1), ('mile', 1), ('superficial', 1), ('hydroxycut', 1), ('emax', 1), ('declofinac', 1), ('c-avazir', 1), ('vita', 1), ('stress', 1), ('sequential', 1), ('utilizing', 1), ('internal', 1), ('derangement', 1), ('protocol', 1), ('without', 1), ('contrast', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter(w.lower() for w in all_english_words)\n",
    "print(word_freq.most_common(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb952026",
   "metadata": {},
   "source": [
    "**Machine Traslation Cleaning (MarianMT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffaf923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/386455109.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"question_body\"] = df[\"question_body\"].astype(str)\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "df[\"question_body\"] = df[\"question_body\"].astype(str)\n",
    "\n",
    "#using FastText LID to Find English Runs\n",
    "lid = fasttext.load_model(\"lid.176.bin\")        \n",
    "\n",
    "def extract_english_phrases(text: str) -> list[str]:\n",
    "    # rough split on whitespace / punctuation\n",
    "    raw_tokens = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    phrases    = []\n",
    "    buf        = []\n",
    "\n",
    "    for tok in raw_tokens:\n",
    "        is_ascii = tok.encode(\"ascii\", \"ignore\").decode(\"ascii\") == tok\n",
    "        if not is_ascii:\n",
    "            flush = True\n",
    "        else:\n",
    "            # fastText predicts labels like \"__label__en\"\n",
    "            lang, conf = lid.predict(tok.lower())\n",
    "            flush = lang[0] != \"__label__en\" or conf[0] < 0.80    # 80 % conf threshold\n",
    "\n",
    "        if flush and buf:\n",
    "            phrases.append(\" \".join(buf))\n",
    "            buf = []\n",
    "        if not flush: \n",
    "            buf.append(tok)\n",
    "\n",
    "    if buf:\n",
    "        phrases.append(\" \".join(buf))\n",
    "    return phrases\n",
    "\n",
    "phrase_docs = [\" \".join(extract_english_phrases(t)) for t in df[\"question_body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 435 TF-IDF-ranked phrases for MT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Rank by TF-IDF, Select top-K phrases\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=str.split,    # treat each phrase as a single token\n",
    "    lowercase=False,\n",
    ")\n",
    "X          = tfidf.fit_transform(phrase_docs)\n",
    "tfidf_sum  = X.sum(axis=0).A1                # global importance score\n",
    "phrases    = np.array(tfidf.get_feature_names_out())\n",
    "phrase2idf = dict(zip(phrases, tfidf_sum))\n",
    "\n",
    "TOP_K = 5000         \n",
    "top_phrases = sorted(phrase2idf, key=phrase2idf.get, reverse=True)[:TOP_K]\n",
    "print(f\"Selected {len(top_phrases)} TF-IDF-ranked phrases for MT\")\n",
    "\n",
    "#Glosary of Common Terms\n",
    "glossary = {\n",
    "\n",
    "    # ─── Organisations & Proper Names ──────────────────────────\n",
    "    \"Tawuniya\": \"التعاونية للتأمين\",\n",
    "\n",
    "    # ─── Medications / Brand-names ─────────────────────────────\n",
    "    \"Voltfast\": \"فولتفاست (ديكلوفيناك بوتاسيوم)\",\n",
    "    \"Primalan\": \"بريمالان (ميكليزين)\",\n",
    "    \"Nurax\":    \"نوركس\",\n",
    "    \"Depojoy\":  \"ديبوجوي\",                \n",
    "    \"Systane Ultra\": \"سايستان ألترا (قطرة مرطبة للعين)\",\n",
    "    \"Systane\":       \"سايستان\",\n",
    "    \"Fluca\":   \"فلوكا (فلوكونازول)\",\n",
    "    \"Regimax\": \"ريجيماكس (مكمل غذائي)\",\n",
    "    \"Chromax\": \"كرومكس (مكمل الكروميوم)\",\n",
    "\n",
    "    # ─── Dental / Ophthalmology / Radiology Terms ─────────────\n",
    "    \"crown\":          \"تاج الأسنان\",\n",
    "    \"spacing\":        \"تباعد الأسنان\",\n",
    "    \"Deep scaling\":   \"تنظيف جذور عميق\",\n",
    "    \"OCT\":            \"التصوير المقطعي البصري (OCT)\",\n",
    "\n",
    "    # ─── Clinical Conditions & Concepts ───────────────────────\n",
    "    \"stroke\":               \"سكتة دماغية\",\n",
    "    \"insulin resistance\":   \"مقاومة الإنسولين\",\n",
    "    \"beta cell function\":   \"وظيفة خلايا بيتا\",\n",
    "    \"complex\":              \"معقدة\",                     \n",
    "    \"Depression\":           \"الاكتئاب\",\n",
    "    \"eye twitching\":        \"رعشة العين\",\n",
    "    \"Right Eye twitching\":  \"رعشة العين اليمنى\",\n",
    "    \"open minded\":          \"منفتح\",\n",
    "\n",
    "    # ─── Laboratory Abbreviations ─────────────────────────────\n",
    "    \"WBC\":  \"خلايا الدم البيضاء (WBC)\",\n",
    "    \"PLT\":  \"الصفائح الدموية (PLT)\",\n",
    "    \"NEUT\": \"العدلات (NEUT)\",\n",
    "\n",
    "    # ─── Catch-alls / Misc. ───────────────────────────────────\n",
    "    \"iq\": \"معدل الذكاء\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de2bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "tok_mt   = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "model_mt = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\").half().eval()\n",
    "translator = pipeline(\"translation\",\n",
    "                      model=model_mt, tokenizer=tok_mt,\n",
    "                      device=0)              \n",
    "\n",
    "# translate in manageable batches\n",
    "def batch_translate(strings, batch_size=64):\n",
    "    out = []\n",
    "    for i in range(0, len(strings), batch_size):\n",
    "        batch = strings[i:i+batch_size]\n",
    "        out.extend(t[\"translation_text\"] for t in translator(batch, max_length=60))\n",
    "    return out\n",
    "\n",
    "translations = batch_translate(top_phrases)    \n",
    "en2ar = dict(zip(top_phrases, translations))  \n",
    "en2ar.update(glossary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fd73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing: 100%|██████████| 82809/82809 [01:41<00:00, 814.51it/s]\n",
      "/tmp/ipykernel_74193/1784610125.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"question_body_mt\"] = [\n"
     ]
    }
   ],
   "source": [
    "# Function to replace phrases in text using a mapping dictionary\n",
    "def replace_phrases(text: str, mapping: dict[str, str]) -> str:\n",
    "    # sort by length so longer phrases replace first\n",
    "    for en in sorted(mapping, key=len, reverse=True):\n",
    "        pattern = re.compile(rf\"\\b{re.escape(en)}\\b\", flags=re.IGNORECASE)\n",
    "        text    = pattern.sub(mapping[en], text)\n",
    "    return text\n",
    "\n",
    "df[\"question_body_mt\"] = [\n",
    "    replace_phrases(txt, en2ar) for txt in tqdm(df[\"question_body\"], desc=\"Replacing\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7660a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the ratio of English words in a text\n",
    "def english_ratio(text):\n",
    "    ascii_tokens = re.findall(r\"\\b[a-zA-Z]+\\b\", text)\n",
    "    ar_tokens    = re.findall(r\"\\b[ء-ي]+\\b\", text)\n",
    "    total = len(ascii_tokens) + len(ar_tokens) or 1\n",
    "    return len(ascii_tokens) / total\n",
    "\n",
    "print(f\"{df['question_body_mt'].apply(english_ratio).mean() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9dc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left-over unique tokens: 1711\n"
     ]
    }
   ],
   "source": [
    "# Check for leftover English tokens\n",
    "leftover = set()\n",
    "\n",
    "for txt in df[\"question_body_mt\"]:          \n",
    "    leftover.update(re.findall(r\"\\b[a-zA-Z][a-zA-Z]+\\b\", txt))\n",
    "\n",
    "print(\"Left-over unique tokens:\", len(leftover)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fd579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "#Residual Cleanup\n",
    "auto = [w for w in leftover if w.islower() or w.istitle()]\n",
    "manual = [w for w in leftover if w.isupper()]\n",
    "\n",
    "# MarianMT single-token pass\n",
    "new_ar = batch_translate(auto, batch_size=128)   \n",
    "en2ar.update(dict(zip(auto, new_ar)))\n",
    "\n",
    "# quick manual mapping examples\n",
    "glossary = {\n",
    "    \"WBC\": \"خلايا الدم البيضاء (WBC)\",\n",
    "    \"MRI\": \"التصوير بالرنين المغناطيسي (MRI)\",\n",
    "    \"IQ\":  \"معدل الذكاء\",\n",
    "}\n",
    "en2ar.update(glossary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final pass to replace any remaining English phrases\n",
    "mask_dirty = df[\"question_body_mt\"].str.contains(r\"[a-zA-Z]\")\n",
    "df.loc[mask_dirty, \"question_body_mt\"] = (\n",
    "    df.loc[mask_dirty, \"question_body_mt\"]\n",
    "      .apply(lambda t: replace_phrases(t, en2ar))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a28a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual English now: 0.05 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the residual English ratio after cleanup\n",
    "residual = df[\"question_body_mt\"].apply(english_ratio).mean() * 100\n",
    "print(f\"Residual English now: {residual:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b42fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/852697260.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['question_body_mt'] = df['question_body_mt'].apply(remove_english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                             استشاره عيون\n",
      "1                     السلام عليكم ممكن دكتور مفاصل واعصاب\n",
      "2            عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم\n",
      "3                                       عمليه الحول للكبار\n",
      "4                                ألم بالكتف الايسر من فترة\n",
      "                               ...                        \n",
      "92554                           اريد التحدث مع طبيبب اسنان\n",
      "92555                عندي قلق مابعد الولاده استشارات نفسيه\n",
      "92556    هل ممكن يدكتور ان تتم عمليه اعاده الكسر بسبب ت...\n",
      "92557                    زوجتي تعاني من ضعف النظر درجة ٤.٥\n",
      "92558                  ابي استفسر عن النظاره الطبيه للعيون\n",
      "Name: question_body_mt, Length: 82809, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/852697260.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['question_body_mt'] = df['question_body_mt'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Function to remove any English words or phrases from the text left after translation\n",
    "def remove_english(text):\n",
    "    # Remove anything that contains Latin characters (even part of a word)\n",
    "    return re.sub(r'[a-zA-Z0-9]+', '', text)\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df['question_body_mt'] = df['question_body_mt'].apply(remove_english)\n",
    "\n",
    "# Clean up extra whitespace and invisible characters\n",
    "df['question_body_mt'] = df['question_body_mt'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(df['question_body_mt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1b9d9",
   "metadata": {},
   "source": [
    "*Preprocessing and using ISRI Stemmer (ISRI Stemmer Pipline)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text using ISRI stemmer\n",
    "def preprocess_text_Isri(text):\n",
    "    # Normalize\n",
    "    text = re.sub(r'[إأآ]', 'ا', text)\n",
    "    text = re.sub(r'ؤ', 'و', text)\n",
    "    text = re.sub(r'ئ', 'ي', text)\n",
    "    text = re.sub(r'ء', '', text)\n",
    "    text = re.sub(r'ة', 'ه', text)\n",
    "\n",
    "    # Remove diacritics\n",
    "    text = re.sub(r'[\\u064B-\\u0652]', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    # Apply tokenization\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    words = [word for word in words if word not in arabic_stopwords]\n",
    "\n",
    "    #Apply stemming\n",
    "    stemmer = ISRIStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cbdb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/3691843459.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"isri_txt\"] = df[\"question_body_mt\"].apply(preprocess_text_Isri)\n"
     ]
    }
   ],
   "source": [
    "df[\"isri_txt\"] = df[\"question_body_mt\"].apply(preprocess_text_Isri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84515833",
   "metadata": {},
   "source": [
    "*Preprocessing & Using PorterStemmer (PorterStemmer Pipline)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text using Porter stemmer\n",
    "def preprocess_text_Porter(text):\n",
    "    # Normalize\n",
    "    text = re.sub(r'[إأآ]', 'ا', text)\n",
    "    text = re.sub(r'ؤ', 'و', text)\n",
    "    text = re.sub(r'ئ', 'ي', text)\n",
    "    text = re.sub(r'ء', '', text)\n",
    "    text = re.sub(r'ة', 'ه', text)\n",
    "\n",
    "    # Remove diacritics\n",
    "    text = re.sub(r'[\\u064B-\\u0652]', '', text)\n",
    "\n",
    "    # Remove punctuation, numbers, English letters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    # Apply tokenization\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    words = [word for word in words if word not in arabic_stopwords]\n",
    "\n",
    "    #Apply stemming\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7df6bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/982068266.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"porter_txt\"]  = df[\"question_body_mt\"].apply(preprocess_text_Porter)\n"
     ]
    }
   ],
   "source": [
    "df[\"porter_txt\"]  = df[\"question_body_mt\"].apply(preprocess_text_Porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c51446",
   "metadata": {},
   "source": [
    "*Preprocessing & Using Snowball Stemmer (SnowballStemmer Pipline)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40727553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text using Snowball stemmer\n",
    "snowball = SnowballStemmer(\"arabic\")\n",
    "\n",
    "def preprocess_text_Snowball(text: str) -> list[str]:\n",
    "    # 1) Normalize & strip diacritics/punctuation\n",
    "    txt = re.sub(r'[إأآ]', 'ا', text)\n",
    "    txt = re.sub(r'ؤ', 'و', txt)\n",
    "    txt = re.sub(r'ئ', 'ي', txt)\n",
    "    txt = re.sub(r'ء',  '' , txt)\n",
    "    txt = re.sub(r'ة', 'ه', txt)\n",
    "    txt = re.sub(r'[\\u064B-\\u0652]', '', txt)   # remove tashkeel\n",
    "    txt = re.sub(r'[^\\w\\s]', ' ', txt)           # remove punctuation\n",
    "    \n",
    "    # 2) Tokenize & remove stopwords\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    tokens = [w for w in tokens if w not in arabic_stopwords]\n",
    "    \n",
    "    # 3) Snowball stemming\n",
    "    stems = [snowball.stem(w) for w in tokens]\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "132c2370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/1483515728.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"snowball_txt\"] = df[\"question_body_mt\"].apply(preprocess_text_Snowball)\n"
     ]
    }
   ],
   "source": [
    "df[\"snowball_txt\"] = df[\"question_body_mt\"].apply(preprocess_text_Snowball)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2f243",
   "metadata": {},
   "source": [
    "*Base Model For Testing Stemmers (NB)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55c54866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model for testing Stemmers\n",
    "def NB_Stemming_Test(col_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[col_name], df[\"specialty_id\"], test_size=0.3,\n",
    "        random_state=42, stratify=df[\"specialty_id\"]\n",
    "    )\n",
    "\n",
    "    X_train = X_train.apply(lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "    X_test  = X_test.apply( lambda x: \" \".join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "\n",
    "    tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n",
    "    Xtr = tfidf.fit_transform(X_train)\n",
    "    Xte = tfidf.transform(X_test)\n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(Xtr, y_train)\n",
    "    y_pred = nb.predict(Xte)\n",
    "\n",
    "    acc  = accuracy_score(y_test,     y_pred)\n",
    "    f1   = f1_score    (y_test,     y_pred, average=\"weighted\")\n",
    "    prec = precision_score(y_test,  y_pred, average=\"weighted\")\n",
    "    rec  = recall_score   (y_test,  y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n=== {col_name} | MultinomialNB ===\")\n",
    "    print(f\"Accuracy : {acc:.3f}\")\n",
    "    print(f\"F1       : {f1:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall   : {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f9065f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== porter_txt | MultinomialNB ===\n",
      "Accuracy : 0.869\n",
      "F1       : 0.870\n",
      "Precision: 0.882\n",
      "Recall   : 0.869\n",
      "\n",
      "=== isri_txt | MultinomialNB ===\n",
      "Accuracy : 0.879\n",
      "F1       : 0.879\n",
      "Precision: 0.889\n",
      "Recall   : 0.879\n",
      "\n",
      "=== snowball_txt | MultinomialNB ===\n",
      "Accuracy : 0.879\n",
      "F1       : 0.879\n",
      "Precision: 0.889\n",
      "Recall   : 0.879\n"
     ]
    }
   ],
   "source": [
    "for col in [\"porter_txt\", \"isri_txt\",\"snowball_txt\"]:\n",
    "    NB_Stemming_Test(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b94f6b",
   "metadata": {},
   "source": [
    "**Checking for mislabled data and correcting it using Semi-Supervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/2234444058.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['question_body_mt'] = df['question_body_mt'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure all values in question_body are strings\n",
    "df['question_body_mt'] = df['question_body_mt'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X = vectorizer.fit_transform(df['question_body_mt'])\n",
    "y = df['specialty_id']\n",
    "\n",
    "# Split into a small trusted training set and the rest\n",
    "X_train, X_check, y_train, y_check, idx_train, idx_check = train_test_split(\n",
    "    X, y, df.index, test_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ca40959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        question_body_mt  specialty_id  \\\n",
      "65088                                         دكتور نفسي            25   \n",
      "81893                 عندي صداع حاد والم في عيوني ورقبتي            14   \n",
      "62372                                علاج بروده في القدم            18   \n",
      "7578                                      كسر في الترقوة            91   \n",
      "87720  السلام عليكم. عندي ولد عمره سنوات فيه خوف من ا...            25   \n",
      "58983                                  اريد ازيد من وزني            91   \n",
      "38509                                         الم الرقبه            18   \n",
      "83898                         الضغط واللام الظهر الشديده            25   \n",
      "79620                                          طبيب عيون            91   \n",
      "87543            انا انسه وعندي سنه ومحتاجه اخس وزن طولي            91   \n",
      "\n",
      "       predicted_label  confidence  \n",
      "65088               91    0.970963  \n",
      "81893               23    0.941356  \n",
      "62372               14    0.974270  \n",
      "7578                14    0.950165  \n",
      "87720               91    0.905723  \n",
      "58983               25    0.960396  \n",
      "38509               14    0.967856  \n",
      "83898               14    0.952056  \n",
      "79620               23    0.965595  \n",
      "87543               25    0.964918  \n"
     ]
    }
   ],
   "source": [
    "# Add predictions and confidence\n",
    "probs = model.predict_proba(X_check)\n",
    "preds = model.predict(X_check)\n",
    "confidence = np.max(probs, axis=1)\n",
    "\n",
    "# Slice original DataFrame correctly\n",
    "df_check = df.loc[idx_check].copy()\n",
    "\n",
    "df_check['predicted_label'] = preds\n",
    "df_check['confidence'] = confidence\n",
    "df_check['mismatch'] = df_check['predicted_label'] != df_check['specialty_id']\n",
    "\n",
    "# Show likely mislabeled rows\n",
    "likely_wrong = df_check[(df_check['mismatch']) & (df_check['confidence'] > 0.9)]\n",
    "print(likely_wrong[['question_body_mt', 'specialty_id', 'predicted_label', 'confidence']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9655cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specialty_id</th>\n",
       "      <th>name_ar</th>\n",
       "      <th>question_body</th>\n",
       "      <th>has_english</th>\n",
       "      <th>english_words</th>\n",
       "      <th>question_body_mt</th>\n",
       "      <th>isri_txt</th>\n",
       "      <th>porter_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>استشاره عيون</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>استشاره عيون</td>\n",
       "      <td>[شار, عين]</td>\n",
       "      <td>[استشاره, عيون]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>السلام عليكم ممكن دكتور مفاصل واعصاب</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>السلام عليكم ممكن دكتور مفاصل واعصاب</td>\n",
       "      <td>[سلم, علي, مكن, دكتور, فصل, عصب]</td>\n",
       "      <td>[السلام, عليكم, ممكن, دكتور, مفاصل, واعصاب]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم</td>\n",
       "      <td>[عند, نقص, يتم, مكن, خدم, معه, سيم]</td>\n",
       "      <td>[عندي, نقص, فيتامين, ممكن, استخدم, معه, كالسيوم]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>عمليه الحول للكبار</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>عمليه الحول للكبار</td>\n",
       "      <td>[عمل, حول, كبر]</td>\n",
       "      <td>[عمليه, الحول, للكبار]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>ألم بالكتف الايسر من فترة</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>ألم بالكتف الايسر من فترة</td>\n",
       "      <td>[الم, كتف, يسر, فتر]</td>\n",
       "      <td>[الم, بالكتف, الايسر, فتره]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>تخدير في الخد شمال نزولا الى الفم</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>تخدير في الخد شمال نزولا الى الفم</td>\n",
       "      <td>[خدر, لخد, نزل, الى, لفم]</td>\n",
       "      <td>[تخدير, الخد, نزولا, الى, الفم]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>استيقظت من النوم قدمي من تحت زر الكعب تؤلم الم...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>استيقظت من النوم قدمي من تحت زر الكعب تؤلم الم...</td>\n",
       "      <td>[يقظ, نوم, قدم, زر, كعب, ولم, الم, شدد, الم, ز...</td>\n",
       "      <td>[استيقظت, النوم, قدمي, زر, الكعب, تولم, الم, ش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>طب عيون</td>\n",
       "      <td>ابني عمره ٦ سنوات عينه حمراء و مليئه بالغمز اه...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>ابني عمره ٦ سنوات عينه حمراء و مليئه بالغمز اه...</td>\n",
       "      <td>[ابن, عمر, ٦, سنو, عين, حمر, ليه, غمز, هرض, رم...</td>\n",
       "      <td>[ابني, عمره, ٦, سنوات, عينه, حمرا, ملييه, بالغ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>تغذية</td>\n",
       "      <td>كيف أخسر وزن</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>كيف أخسر وزن</td>\n",
       "      <td>[خسر, وزن]</td>\n",
       "      <td>[اخسر, وزن]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>لدى حبوب في اخر لساني من جهات حلق لدي حبوب في حلق</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>لدى حبوب في اخر لساني من جهات حلق لدي حبوب في حلق</td>\n",
       "      <td>[حبب, اخر, لسا, جهت, حلق, لدي, حبب, حلق]</td>\n",
       "      <td>[حبوب, اخر, لساني, جهات, حلق, لدي, حبوب, حلق]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>عدم انشراح بالصدر</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>عدم انشراح بالصدر</td>\n",
       "      <td>[عدم, شرح, صدر]</td>\n",
       "      <td>[عدم, انشراح, بالصدر]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>الم اسنان شديد</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>الم اسنان شديد</td>\n",
       "      <td>[الم, اسن, شدد]</td>\n",
       "      <td>[الم, اسنان, شديد]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91</td>\n",
       "      <td>الطب النفسي</td>\n",
       "      <td>أكتئاب و العصبيه المفرطة والتوتر وعدم الاحساس ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>أكتئاب و العصبيه المفرطة والتوتر وعدم الاحساس ...</td>\n",
       "      <td>[كيب, عصب, فرط, وتر, عدم, حسس, شعر]</td>\n",
       "      <td>[اكتياب, العصبيه, المفرطه, والتوتر, وعدم, الاح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>طب اسنان</td>\n",
       "      <td>ابي طبيب استان</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>ابي طبيب استان</td>\n",
       "      <td>[ابي, طبب, است]</td>\n",
       "      <td>[ابي, طبيب, استان]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>جراحة العظام والمفاصل</td>\n",
       "      <td>طفل ٧ سنوات عنده كسر في الزراع</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>طفل ٧ سنوات عنده كسر في الزراع</td>\n",
       "      <td>[طفل, ٧, سنو, عند, كسر, زرع]</td>\n",
       "      <td>[طفل, ٧, سنوات, عنده, كسر, الزراع]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    specialty_id                name_ar  \\\n",
       "0             23                طب عيون   \n",
       "1             14  جراحة العظام والمفاصل   \n",
       "2             14  جراحة العظام والمفاصل   \n",
       "3             23                طب عيون   \n",
       "4             14  جراحة العظام والمفاصل   \n",
       "5             18               طب اسنان   \n",
       "6             14  جراحة العظام والمفاصل   \n",
       "7             23                طب عيون   \n",
       "8             25                  تغذية   \n",
       "9             18               طب اسنان   \n",
       "10            91            الطب النفسي   \n",
       "11            18               طب اسنان   \n",
       "12            91            الطب النفسي   \n",
       "13            18               طب اسنان   \n",
       "14            14  جراحة العظام والمفاصل   \n",
       "\n",
       "                                        question_body  has_english  \\\n",
       "0                                        استشاره عيون        False   \n",
       "1                السلام عليكم ممكن دكتور مفاصل واعصاب        False   \n",
       "2       عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم        False   \n",
       "3                                  عمليه الحول للكبار        False   \n",
       "4                           ألم بالكتف الايسر من فترة        False   \n",
       "5                   تخدير في الخد شمال نزولا الى الفم        False   \n",
       "6   استيقظت من النوم قدمي من تحت زر الكعب تؤلم الم...        False   \n",
       "7   ابني عمره ٦ سنوات عينه حمراء و مليئه بالغمز اه...        False   \n",
       "8                                        كيف أخسر وزن        False   \n",
       "9   لدى حبوب في اخر لساني من جهات حلق لدي حبوب في حلق        False   \n",
       "10                                  عدم انشراح بالصدر        False   \n",
       "11                                     الم اسنان شديد        False   \n",
       "12  أكتئاب و العصبيه المفرطة والتوتر وعدم الاحساس ...        False   \n",
       "13                                     ابي طبيب استان        False   \n",
       "14                     طفل ٧ سنوات عنده كسر في الزراع        False   \n",
       "\n",
       "   english_words                                   question_body_mt  \\\n",
       "0             []                                       استشاره عيون   \n",
       "1             []               السلام عليكم ممكن دكتور مفاصل واعصاب   \n",
       "2             []      عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم   \n",
       "3             []                                 عمليه الحول للكبار   \n",
       "4             []                          ألم بالكتف الايسر من فترة   \n",
       "5             []                  تخدير في الخد شمال نزولا الى الفم   \n",
       "6             []  استيقظت من النوم قدمي من تحت زر الكعب تؤلم الم...   \n",
       "7             []  ابني عمره ٦ سنوات عينه حمراء و مليئه بالغمز اه...   \n",
       "8             []                                       كيف أخسر وزن   \n",
       "9             []  لدى حبوب في اخر لساني من جهات حلق لدي حبوب في حلق   \n",
       "10            []                                  عدم انشراح بالصدر   \n",
       "11            []                                     الم اسنان شديد   \n",
       "12            []  أكتئاب و العصبيه المفرطة والتوتر وعدم الاحساس ...   \n",
       "13            []                                     ابي طبيب استان   \n",
       "14            []                     طفل ٧ سنوات عنده كسر في الزراع   \n",
       "\n",
       "                                             isri_txt  \\\n",
       "0                                          [شار, عين]   \n",
       "1                    [سلم, علي, مكن, دكتور, فصل, عصب]   \n",
       "2                 [عند, نقص, يتم, مكن, خدم, معه, سيم]   \n",
       "3                                     [عمل, حول, كبر]   \n",
       "4                                [الم, كتف, يسر, فتر]   \n",
       "5                           [خدر, لخد, نزل, الى, لفم]   \n",
       "6   [يقظ, نوم, قدم, زر, كعب, ولم, الم, شدد, الم, ز...   \n",
       "7   [ابن, عمر, ٦, سنو, عين, حمر, ليه, غمز, هرض, رم...   \n",
       "8                                          [خسر, وزن]   \n",
       "9            [حبب, اخر, لسا, جهت, حلق, لدي, حبب, حلق]   \n",
       "10                                    [عدم, شرح, صدر]   \n",
       "11                                    [الم, اسن, شدد]   \n",
       "12                [كيب, عصب, فرط, وتر, عدم, حسس, شعر]   \n",
       "13                                    [ابي, طبب, است]   \n",
       "14                       [طفل, ٧, سنو, عند, كسر, زرع]   \n",
       "\n",
       "                                           porter_txt  \n",
       "0                                     [استشاره, عيون]  \n",
       "1         [السلام, عليكم, ممكن, دكتور, مفاصل, واعصاب]  \n",
       "2    [عندي, نقص, فيتامين, ممكن, استخدم, معه, كالسيوم]  \n",
       "3                              [عمليه, الحول, للكبار]  \n",
       "4                         [الم, بالكتف, الايسر, فتره]  \n",
       "5                     [تخدير, الخد, نزولا, الى, الفم]  \n",
       "6   [استيقظت, النوم, قدمي, زر, الكعب, تولم, الم, ش...  \n",
       "7   [ابني, عمره, ٦, سنوات, عينه, حمرا, ملييه, بالغ...  \n",
       "8                                         [اخسر, وزن]  \n",
       "9       [حبوب, اخر, لساني, جهات, حلق, لدي, حبوب, حلق]  \n",
       "10                              [عدم, انشراح, بالصدر]  \n",
       "11                                 [الم, اسنان, شديد]  \n",
       "12  [اكتياب, العصبيه, المفرطه, والتوتر, وعدم, الاح...  \n",
       "13                                 [ابي, طبيب, استان]  \n",
       "14                 [طفل, ٧, سنوات, عنده, كسر, الزراع]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically fix highly confident wrong labels\n",
    "df.loc[likely_wrong.index, 'specialty_id'] = likely_wrong['predicted_label']\n",
    "\n",
    "# Optional: save for review\n",
    "likely_wrong.to_csv(\"review_mislabeled_questions.csv\", index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71d45add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected labels: 182\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corrected labels: {len(likely_wrong)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8694c",
   "metadata": {},
   "source": [
    "**Word Embediing Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f068e",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "179b32c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: (82809, 332612)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(min_df=1, ngram_range=(1,2))\n",
    "X_tfidf  = tfidf_vec.fit_transform(df['isri_txt'].astype(str))\n",
    "print('TF-IDF:', X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd015fb",
   "metadata": {},
   "source": [
    "BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55c9d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: (82809, 17476)\n"
     ]
    }
   ],
   "source": [
    "bow_vec = CountVectorizer(min_df=1)\n",
    "X_bow = bow_vec.fit_transform(df['isri_txt'].astype(str))\n",
    "print('BoW:', X_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec03b64",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e5da269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec: (82809, 100)\n"
     ]
    }
   ],
   "source": [
    "sentences = df['isri_txt'].tolist()\n",
    "w2v = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=2, epochs=20)\n",
    "X_w2v = np.vstack([\n",
    "    np.mean([w2v.wv[w] for w in s if w in w2v.wv] or [np.zeros(100)], axis=0)\n",
    "    for s in sentences])\n",
    "print('Word2Vec:', X_w2v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774c8b3",
   "metadata": {},
   "source": [
    "FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9633685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText: (82809, 100)\n"
     ]
    }
   ],
   "source": [
    "ft = FastText(sentences, vector_size=100, window=5, min_count=1, workers=2, epochs=20)\n",
    "X_ft = np.vstack([\n",
    "    np.mean([ft.wv[w] for w in s if w in ft.wv] or [np.zeros(100)], axis=0)\n",
    "    for s in sentences])\n",
    "print('FastText:', X_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9669f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['specialty_id'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a47f3f",
   "metadata": {},
   "source": [
    "*First Base model for Word Embedding Comparison (Naive Bayes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate word embeddings using SVM model\n",
    "def svm_eval(X, name):\n",
    "    # 1) train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=Y\n",
    "    )\n",
    "\n",
    "    # 2) build & train the SVM\n",
    "    clf = LinearSVC(C=1.0,max_iter=10_000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 3) predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 4) compute metrics\n",
    "    acc  = accuracy_score(y_test,    y_pred)\n",
    "    f1   = f1_score    (y_test,    y_pred, average=\"weighted\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    rec  = recall_score   (y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    # 5) report\n",
    "    print(\n",
    "        f\"[SVM] {name}: \"\n",
    "        f\"Acc {acc:.3f} | \"\n",
    "        f\"F1 {f1:.3f} | \"\n",
    "        f\"Precision {prec:.3f} | \"\n",
    "        f\"Recall {rec:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "103b336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM] TF‑IDF: Acc 0.907 | F1 0.907 | Precision 0.909 | Recall 0.907\n",
      "[SVM] BoW: Acc 0.896 | F1 0.896 | Precision 0.897 | Recall 0.896\n",
      "[SVM] Word2Vec: Acc 0.891 | F1 0.891 | Precision 0.893 | Recall 0.891\n",
      "[SVM] FastText: Acc 0.890 | F1 0.890 | Precision 0.891 | Recall 0.890\n"
     ]
    }
   ],
   "source": [
    "for name, X in {'TF‑IDF':X_tfidf,'BoW':X_bow,'Word2Vec':X_w2v,'FastText':X_ft}.items():\n",
    "    svm_eval(X,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da64ba",
   "metadata": {},
   "source": [
    "Tokenization for NN model (BidirectionalGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Vocabulary Preparation\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['isri_txt'])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences and pad them\n",
    "seqs = tokenizer.texts_to_sequences(df['isri_txt'])\n",
    "MAX_LEN = 50                             \n",
    "X_pad  = pad_sequences(seqs, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "# one-hot labels (specialty_id is the target column)\n",
    "y_cat = to_categorical(df['specialty_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding Matrices\n",
    "EMB_DIM = 100\n",
    "VOCAB   = vocab_size \n",
    "def make_matrix(model):\n",
    "    mat = np.zeros((VOCAB, EMB_DIM))\n",
    "    for word, idx in word_index.items():\n",
    "        if idx < VOCAB and word in model.wv:\n",
    "            mat[idx] = model.wv[word]\n",
    "    return mat\n",
    "\n",
    "w2v_mat = make_matrix(w2v) \n",
    "ft_mat  = make_matrix(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbae174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pad, y_cat, test_size=0.2,\n",
    "    stratify=df['specialty_id'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd4ebe",
   "metadata": {},
   "source": [
    "*Second Base model for Word Embedding Comparison (BIdirectionalGRU)*\n",
    "this model only tests Word2vec and Fasttext because Rnn's work on sequentional word embeddings only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the BiGRU model\n",
    "def build_bigru(emb_matrix, name):\n",
    "    emb_matrix = emb_matrix.astype(\"float32\")\n",
    "\n",
    "    model = Sequential(name=name)\n",
    "    model.add(Embedding(input_dim=VOCAB,output_dim=EMB_DIM,input_length=MAX_LEN,weights=[emb_matrix],trainable=False,dtype=\"float32\",mask_zero=False))\n",
    "\n",
    "    \n",
    "    model.add(Bidirectional(\n",
    "        GRU( 128,return_sequences=False,reset_after=False,recurrent_activation=\"sigmoid\",implementation=1)))\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(y_cat.shape[1], activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c6275",
   "metadata": {},
   "source": [
    "BiDirectionalGRU with Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba206b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 116ms/step - accuracy: 0.6906 - loss: 1.3631 - val_accuracy: 0.8992 - val_loss: 0.3040\n",
      "Epoch 2/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - accuracy: 0.9020 - loss: 0.2960 - val_accuracy: 0.9034 - val_loss: 0.2904\n",
      "Epoch 3/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 116ms/step - accuracy: 0.9097 - loss: 0.2737 - val_accuracy: 0.9037 - val_loss: 0.2835\n",
      "Epoch 4/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 115ms/step - accuracy: 0.9123 - loss: 0.2634 - val_accuracy: 0.9067 - val_loss: 0.2823\n",
      "[GRU + Word2Vec]  Acc=0.905  F1=0.905  Precision=0.906  Recall=0.905\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the BiGRU model with Word2Vec embeddings\n",
    "gru_w2v = build_bigru(w2v_mat, \"GRU_W2V\")\n",
    "gru_w2v.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=4, batch_size=256,\n",
    "    validation_split=0.1, verbose=1\n",
    ")\n",
    "\n",
    "y_pred = np.argmax(gru_w2v.predict(X_test, verbose=0), axis=1)\n",
    "y_true = np.argmax(y_test,    axis=1)\n",
    "\n",
    "acc  = accuracy_score(y_true, y_pred)\n",
    "f1   = f1_score    (y_true, y_pred, average='weighted')\n",
    "prec = precision_score(y_true, y_pred, average='weighted')\n",
    "rec  = recall_score   (y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\n",
    "    f\"[GRU + Word2Vec]  \"\n",
    "    f\"Acc={acc:.3f}  \"\n",
    "    f\"F1={f1:.3f}  \"\n",
    "    f\"Precision={prec:.3f}  \"\n",
    "    f\"Recall={rec:.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691a8b7",
   "metadata": {},
   "source": [
    "Bidirectional with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - accuracy: 0.7002 - loss: 1.3475 - val_accuracy: 0.9017 - val_loss: 0.3093\n",
      "Epoch 2/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 114ms/step - accuracy: 0.9003 - loss: 0.3068 - val_accuracy: 0.9004 - val_loss: 0.2981\n",
      "Epoch 3/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 114ms/step - accuracy: 0.9067 - loss: 0.2814 - val_accuracy: 0.9032 - val_loss: 0.2906\n",
      "Epoch 4/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 114ms/step - accuracy: 0.9149 - loss: 0.2562 - val_accuracy: 0.9035 - val_loss: 0.2855\n",
      "[GRU + FastText]  Acc=0.906  F1=0.906  Precision=0.907  Recall=0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the BiGRU model with FastText embeddings\n",
    "gru_ft = build_bigru(ft_mat, \"GRU_FT\")\n",
    "gru_ft.fit(X_train, y_train, epochs=4, batch_size=256,\n",
    "           validation_split=0.1, verbose=1)\n",
    "\n",
    "y_pred = np.argmax(gru_ft.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "acc  = accuracy_score(y_true, y_pred)\n",
    "f1   = f1_score    (y_true, y_pred, average='weighted')\n",
    "prec = precision_score(y_true, y_pred, average='weighted')\n",
    "rec  = recall_score   (y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\n",
    "    f\"[GRU + FastText]  \"\n",
    "    f\"Acc={acc:.3f}  \"\n",
    "    f\"F1={f1:.3f}  \"\n",
    "    f\"Precision={prec:.3f}  \"\n",
    "    f\"Recall={rec:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ec788",
   "metadata": {},
   "source": [
    "**Testing the Best Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6b844",
   "metadata": {},
   "source": [
    "*Train Test Split For NB* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare FastText embeddings for classification\n",
    "sentences = df['isri_txt'].tolist()\n",
    "FT_DIM    = ft.vector_size\n",
    "doc_vecs  = np.vstack([\n",
    "    np.mean([ft.wv[w] for w in sent] or [np.zeros(FT_DIM)], axis=0)\n",
    "    for sent in sentences\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets for GNB\n",
    "X_tr_FT, X_te_FT, y_tr_lbl, y_te_lbl = train_test_split(\n",
    "    doc_vecs, df['specialty_id'],\n",
    "    test_size=0.2, stratify=df['specialty_id'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39392dd",
   "metadata": {},
   "source": [
    "*Train Test Split For RNN's*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate For RNN's\n",
    "X_tr_seq, X_te_seq, y_tr_cat, y_te_cat = train_test_split(\n",
    "    X_pad, y_cat,\n",
    "    test_size=0.2, stratify=df['specialty_id'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b152e3",
   "metadata": {},
   "source": [
    "*Gussian Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49786b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FastText + GNB]  Acc=0.854  F1=0.856  Precision=0.860  Recall=0.854\n"
     ]
    }
   ],
   "source": [
    "# Train Gaussian Naive Bayes on FastText embeddings\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_tr_FT, y_tr_lbl)\n",
    "y_pred = gnb.predict(X_te_FT)\n",
    "\n",
    "acc  = accuracy_score(y_te_lbl, y_pred)\n",
    "f1   = f1_score    (y_te_lbl, y_pred, average='weighted')\n",
    "prec = precision_score(y_te_lbl, y_pred, average='weighted')\n",
    "rec  = recall_score   (y_te_lbl, y_pred, average='weighted')\n",
    "\n",
    "print(\n",
    "    f\"[FastText + GNB]  \"\n",
    "    f\"Acc={acc:.3f}  \"\n",
    "    f\"F1={f1:.3f}  \"\n",
    "    f\"Precision={prec:.3f}  \"\n",
    "    f\"Recall={rec:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the FastText embedding matrix for Keras\n",
    "EMB_DIM = 100\n",
    "VOCAB   = vocab_size \n",
    "def make_matrix(model):\n",
    "    mat = np.zeros((VOCAB, EMB_DIM))\n",
    "    for word, idx in word_index.items():\n",
    "        if idx < VOCAB and word in model.wv:\n",
    "            mat[idx] = model.wv[word]\n",
    "    return mat\n",
    " \n",
    "ft_mat  = make_matrix(ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fe70b",
   "metadata": {},
   "source": [
    "*Base Structure for both GRU and LSTM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a BiGRU and LSTM model\n",
    "def build_bigru_or_lstm(cell_class, name):\n",
    "    model = Sequential(name=name)\n",
    "    \n",
    "    model.add(Embedding(\n",
    "        input_dim=VOCAB, output_dim=EMB_DIM, input_length=X_pad.shape[1],\n",
    "        weights=[ft_mat], trainable=False))\n",
    "    \n",
    "    model.add(Bidirectional(cell_class(128)))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e6b19",
   "metadata": {},
   "source": [
    "*GRU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8ac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 119ms/step - accuracy: 0.6776 - loss: 1.3624 - val_accuracy: 0.8951 - val_loss: 0.3071\n",
      "Epoch 2/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - accuracy: 0.9008 - loss: 0.3001 - val_accuracy: 0.9045 - val_loss: 0.2945\n",
      "Epoch 3/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - accuracy: 0.9065 - loss: 0.2855 - val_accuracy: 0.9048 - val_loss: 0.2901\n",
      "Epoch 4/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - accuracy: 0.9121 - loss: 0.2639 - val_accuracy: 0.9075 - val_loss: 0.2820\n",
      "[FastText + BiGRU]  Acc=0.906  F1=0.907  Precision=0.909  Recall=0.906\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the BiGRU model with FastText embeddings\n",
    "gru_ft = build_bigru_or_lstm(GRU, \"GRU_FT\")\n",
    "gru_ft.fit(X_tr_seq, y_tr_cat, epochs=4, batch_size=256,\n",
    "           validation_split=0.1, verbose=1)\n",
    "\n",
    "y_pred = np.argmax(gru_ft.predict(X_te_seq, verbose=0), axis=1)\n",
    "y_true = np.argmax(y_te_cat, axis=1)\n",
    "\n",
    "acc  = accuracy_score(y_true, y_pred)\n",
    "f1   = f1_score    (y_true, y_pred, average='weighted')\n",
    "prec = precision_score(y_true, y_pred, average='weighted')\n",
    "rec  = recall_score   (y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\n",
    "    f\"[FastText + BiGRU]  \"\n",
    "    f\"Acc={acc:.3f}  \"\n",
    "    f\"F1={f1:.3f}  \"\n",
    "    f\"Precision={prec:.3f}  \"\n",
    "    f\"Recall={rec:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37c921",
   "metadata": {},
   "source": [
    "*LSTM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ada66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.6998 - loss: 1.2992 - val_accuracy: 0.9010 - val_loss: 0.3074\n",
      "Epoch 2/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 122ms/step - accuracy: 0.9012 - loss: 0.3039 - val_accuracy: 0.9048 - val_loss: 0.2912\n",
      "Epoch 3/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 123ms/step - accuracy: 0.9091 - loss: 0.2738 - val_accuracy: 0.9045 - val_loss: 0.2906\n",
      "Epoch 4/4\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.9119 - loss: 0.2609 - val_accuracy: 0.9063 - val_loss: 0.2903\n",
      "[FastText + BiLSTM]  Acc=0.906  F1=0.907  Precision=0.908  Recall=0.906\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the LSTM model with FastText embeddings\n",
    "lstm_ft = build_bigru_or_lstm(LSTM, \"LSTM_FT\")\n",
    "lstm_ft.fit(X_tr_seq, y_tr_cat, epochs=4, batch_size=256,\n",
    "            validation_split=0.1, verbose=1)\n",
    "\n",
    "y_pred = np.argmax(lstm_ft.predict(X_te_seq, verbose=0), axis=1)\n",
    "\n",
    "acc   = accuracy_score(y_true,     y_pred)\n",
    "f1    = f1_score    (y_true,     y_pred, average=\"weighted\")\n",
    "prec  = precision_score(y_true,  y_pred, average=\"weighted\")\n",
    "rec   = recall_score   (y_true,  y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"[FastText + BiLSTM]  \"\n",
    "      f\"Acc={acc:.3f}  \"\n",
    "      f\"F1={f1:.3f}  \"\n",
    "      f\"Precision={prec:.3f}  \"\n",
    "      f\"Recall={rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4107f7c",
   "metadata": {},
   "source": [
    "**Text Classification (Bert & GPT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5985eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/990594858.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"specialty_id\"].astype(\"category\").cat.codes\n"
     ]
    }
   ],
   "source": [
    "# Convert specialty_id to a categorical label\n",
    "df[\"label\"] = df[\"specialty_id\"].astype(\"category\").cat.codes\n",
    "num_labels  = df[\"label\"].nunique()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df[[\"question_body_mt\", \"label\"]],\n",
    "    test_size=0.2, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "ds_train = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "ds_test  = Dataset.from_pandas(test_df .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c78ed",
   "metadata": {},
   "source": [
    "**Arabert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Set the device for PyTorch\n",
    "MODEL_ID = \"aubmindlab/bert-base-arabertv02\"\n",
    "tok   = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_ID, num_labels=num_labels).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bca013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 66247/66247 [00:07<00:00, 8615.03 examples/s]\n",
      "Map: 100%|██████████| 16562/16562 [00:01<00:00, 9655.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization function for the dataset\n",
    "def tok_fn(batch):\n",
    "    return tok(batch[\"question_body_mt\"],\n",
    "               truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "ds_train = ds_train.map(tok_fn, batched=True,\n",
    "                        remove_columns=[\"question_body_mt\"])\n",
    "ds_test  = ds_test .map(tok_fn, batched=True,\n",
    "                        remove_columns=[\"question_body_mt\"])\n",
    "\n",
    "ds_train.set_format(type=\"torch\")\n",
    "ds_test .set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders for training and testing\n",
    "collator = DataCollatorWithPadding(tok)\n",
    "train_loader = DataLoader(ds_train, batch_size=16, shuffle=True,\n",
    "                          collate_fn=collator, pin_memory=(device==\"cuda\"))\n",
    "test_loader  = DataLoader(ds_test,  batch_size=32, shuffle=False,\n",
    "                          collate_fn=collator, pin_memory=(device==\"cuda\"))\n",
    "\n",
    "print(\"DataLoaders ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/87510863.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler      = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
      "/tmp/ipykernel_74193/87510863.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Epoch 1 | avg loss = 0.3019\n",
      "✓ Epoch 2 | avg loss = 0.2193\n",
      "✓ Epoch 3 | avg loss = 0.1825\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "optimizer  = AdamW(model.parameters(), lr=2e-5)\n",
    "grad_accum = 2\n",
    "scaler      = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "for epoch in range(1, 4):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            out  = model(**batch)\n",
    "            loss = out.loss / grad_accum\n",
    "        scaler.scale(loss).backward()\n",
    "        if step % grad_accum == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        total_loss += loss.item() * grad_accum\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✓ Epoch {epoch} | avg loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.918, 'F1': 0.918, 'Precision': 0.918, 'Recall': 0.918}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = model(**batch).logits\n",
    "        preds  = logits.argmax(dim=-1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "preds  = np.concatenate(all_preds)\n",
    "labels = np.concatenate(all_labels)\n",
    "\n",
    "#Compute metrics\n",
    "metric_acc  = evaluate.load(\"accuracy\")\n",
    "metric_f1   = evaluate.load(\"f1\")\n",
    "metric_prec = evaluate.load(\"precision\")\n",
    "metric_rec  = evaluate.load(\"recall\")\n",
    "\n",
    "metric_acc.add_batch(predictions=preds, references=labels)\n",
    "metric_f1 .add_batch(predictions=preds, references=labels)\n",
    "metric_prec.add_batch(predictions=preds, references=labels)\n",
    "metric_rec .add_batch(predictions=preds, references=labels)\n",
    "\n",
    "results = {\n",
    "    \"Accuracy\" : metric_acc.compute()[\"accuracy\"],\n",
    "    \"F1\"       : metric_f1.compute(average=\"weighted\")[\"f1\"],\n",
    "    \"Precision\": metric_prec.compute(average=\"weighted\")[\"precision\"],\n",
    "    \"Recall\"   : metric_rec.compute(average=\"weighted\")[\"recall\"],\n",
    "}\n",
    "rounded_results = {k: round(v, 3) for k, v in results.items()}\n",
    "print(rounded_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c890ccd",
   "metadata": {},
   "source": [
    "**GPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at aubmindlab/aragpt2-base and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "MODEL_ID = \"aubmindlab/aragpt2-base\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Ensure the pad token is set\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Set the device for PyTorch\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_ID, num_labels=num_labels,\n",
    "            pad_token_id=tok.pad_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bd378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 66247/66247 [00:07<00:00, 9138.72 examples/s] \n",
      "Map: 100%|██████████| 16562/16562 [00:01<00:00, 10247.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization function for the dataset\n",
    "def tok_fn(batch):\n",
    "    return tok(batch[\"question_body_mt\"],\n",
    "               truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "ds_train = ds_train.map(tok_fn, batched=True,\n",
    "                        remove_columns=[\"question_body_mt\"])\n",
    "ds_test  = ds_test .map(tok_fn, batched=True,\n",
    "                        remove_columns=[\"question_body_mt\"])\n",
    "ds_train.set_format(\"torch\"); ds_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training and testing\n",
    "collator = DataCollatorWithPadding(tok)\n",
    "train_loader = DataLoader(ds_train, batch_size=16, shuffle=True,\n",
    "                          collate_fn=collator, pin_memory=(device==\"cuda\"))\n",
    "test_loader  = DataLoader(ds_test , batch_size=32, shuffle=False,\n",
    "                          collate_fn=collator, pin_memory=(device==\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc166c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74193/3467616.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
      "/tmp/ipykernel_74193/3467616.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Epoch 1 | avg loss 0.4465\n",
      "✓ Epoch 2 | avg loss 0.2873\n",
      "✓ Epoch 3 | avg loss 0.2433\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "optimizer  = AdamW(model.parameters(), lr=5e-5)   # GPT often likes 5e-5\n",
    "grad_accum = 2\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train(); tot_loss = 0\n",
    "    for step, batch in enumerate(train_loader, 1):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            out = model(**batch)\n",
    "            loss = out.loss / grad_accum\n",
    "        scaler.scale(loss).backward()\n",
    "        if step % grad_accum == 0:\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        tot_loss += loss.item() * grad_accum\n",
    "    print(f\"✓ Epoch {epoch+1} | avg loss {tot_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.905, 'F1': 0.906, 'Precision': 0.908, 'Recall': 0.905}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = model(**batch).logits\n",
    "        preds  = logits.argmax(dim=-1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "preds  = np.concatenate(all_preds)\n",
    "labels = np.concatenate(all_labels)\n",
    "\n",
    "#Compute metrics\n",
    "\n",
    "metric_acc  = evaluate.load(\"accuracy\")\n",
    "metric_f1   = evaluate.load(\"f1\")\n",
    "metric_prec = evaluate.load(\"precision\")\n",
    "metric_rec  = evaluate.load(\"recall\")\n",
    "\n",
    "metric_acc.add_batch(predictions=preds, references=labels)\n",
    "metric_f1 .add_batch(predictions=preds, references=labels)\n",
    "metric_prec.add_batch(predictions=preds, references=labels)\n",
    "metric_rec .add_batch(predictions=preds, references=labels)\n",
    "\n",
    "results = {\n",
    "    \"Accuracy\" : metric_acc.compute()[\"accuracy\"],\n",
    "    \"F1\"       : metric_f1.compute(average=\"weighted\")[\"f1\"],\n",
    "    \"Precision\": metric_prec.compute(average=\"weighted\")[\"precision\"],\n",
    "    \"Recall\"   : metric_rec.compute(average=\"weighted\")[\"recall\"],\n",
    "}\n",
    "rounded_results = {k: round(v, 3) for k, v in results.items()}\n",
    "print(rounded_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
